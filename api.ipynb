{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a34d127",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4a6718",
   "metadata": {},
   "source": [
    "## 1. Setup & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1048c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install flask flask-cors pandas numpy scikit-learn python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "382c6842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, request\n",
    "from flask_cors import CORS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70036e4",
   "metadata": {},
   "source": [
    "## 2. Load Data from Modeling Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "076cd37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA LOADED SUCCESSFULLY\n",
      "============================================================\n",
      "Clustering Results: (514, 6)\n",
      "Cluster Profiles: (3, 11)\n",
      "Cluster Centroids: (3, 3)\n",
      "Integrated Data: (1028, 47)\n",
      "\n",
      "Clustering Results columns:\n",
      "['Kabupaten_Kota', 'Tahun', 'Region', 'Pengeluaran_Buah', 'Pengeluaran_Sayur', 'Cluster']\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kabupaten_Kota</th>\n",
       "      <th>Tahun</th>\n",
       "      <th>Region</th>\n",
       "      <th>Pengeluaran_Buah</th>\n",
       "      <th>Pengeluaran_Sayur</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aceh Barat</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>11160.0</td>\n",
       "      <td>15821.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aceh Barat Daya</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>7231.0</td>\n",
       "      <td>13790.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aceh Besar</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>6689.0</td>\n",
       "      <td>14052.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aceh Jaya</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>8789.0</td>\n",
       "      <td>14197.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aceh Selatan</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>5682.0</td>\n",
       "      <td>14771.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Kabupaten_Kota  Tahun Region  Pengeluaran_Buah  Pengeluaran_Sayur  Cluster\n",
       "0       Aceh Barat   2024   Aceh           11160.0            15821.0        0\n",
       "1  Aceh Barat Daya   2024   Aceh            7231.0            13790.0        1\n",
       "2       Aceh Besar   2024   Aceh            6689.0            14052.0        1\n",
       "3        Aceh Jaya   2024   Aceh            8789.0            14197.0        1\n",
       "4     Aceh Selatan   2024   Aceh            5682.0            14771.0        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define paths\n",
    "DATA_DIR = Path('data/result')\n",
    "CLEANED_DIR = Path('data/cleaned')\n",
    "\n",
    "# Load clustering results\n",
    "clustering_results = pd.read_csv(DATA_DIR / 'clustering_results.csv')\n",
    "cluster_profiles = pd.read_csv(DATA_DIR / 'cluster_profiles.csv')\n",
    "cluster_centroids = pd.read_csv(DATA_DIR / 'cluster_centroids.csv')\n",
    "\n",
    "# Load cleaned data for additional features\n",
    "data_integrated = pd.read_csv(CLEANED_DIR / 'data_integrated_wide.csv')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA LOADED SUCCESSFULLY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Clustering Results: {clustering_results.shape}\")\n",
    "print(f\"Cluster Profiles: {cluster_profiles.shape}\")\n",
    "print(f\"Cluster Centroids: {cluster_centroids.shape}\")\n",
    "print(f\"Integrated Data: {data_integrated.shape}\")\n",
    "print(\"\\nClustering Results columns:\")\n",
    "print(clustering_results.columns.tolist())\n",
    "print(\"\\nSample data:\")\n",
    "clustering_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68946c3a",
   "metadata": {},
   "source": [
    "## 3. Data Processing & Preparation\n",
    "\n",
    "Prepare data untuk API responses dengan enrichment dan transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d20afae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data preparation complete!\n",
      "\n",
      "Enriched data shape: (514, 8)\n",
      "\n",
      "New columns added:\n",
      "['Cluster_Label', 'Cluster_Category']\n",
      "\n",
      "Sample enriched data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kabupaten_Kota</th>\n",
       "      <th>Tahun</th>\n",
       "      <th>Region</th>\n",
       "      <th>Pengeluaran_Buah</th>\n",
       "      <th>Pengeluaran_Sayur</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Cluster_Label</th>\n",
       "      <th>Cluster_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aceh Barat</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>11160.0</td>\n",
       "      <td>15821.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Low Expenditure</td>\n",
       "      <td>Low Expenditure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aceh Barat Daya</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>7231.0</td>\n",
       "      <td>13790.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Balanced Expenditure</td>\n",
       "      <td>Balanced Expenditure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aceh Besar</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>6689.0</td>\n",
       "      <td>14052.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Balanced Expenditure</td>\n",
       "      <td>Balanced Expenditure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aceh Jaya</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>8789.0</td>\n",
       "      <td>14197.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Balanced Expenditure</td>\n",
       "      <td>Balanced Expenditure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aceh Selatan</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>5682.0</td>\n",
       "      <td>14771.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Balanced Expenditure</td>\n",
       "      <td>Balanced Expenditure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Kabupaten_Kota  Tahun Region  Pengeluaran_Buah  Pengeluaran_Sayur  \\\n",
       "0       Aceh Barat   2024   Aceh           11160.0            15821.0   \n",
       "1  Aceh Barat Daya   2024   Aceh            7231.0            13790.0   \n",
       "2       Aceh Besar   2024   Aceh            6689.0            14052.0   \n",
       "3        Aceh Jaya   2024   Aceh            8789.0            14197.0   \n",
       "4     Aceh Selatan   2024   Aceh            5682.0            14771.0   \n",
       "\n",
       "   Cluster         Cluster_Label      Cluster_Category  \n",
       "0        0       Low Expenditure       Low Expenditure  \n",
       "1        1  Balanced Expenditure  Balanced Expenditure  \n",
       "2        1  Balanced Expenditure  Balanced Expenditure  \n",
       "3        1  Balanced Expenditure  Balanced Expenditure  \n",
       "4        1  Balanced Expenditure  Balanced Expenditure  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_cluster_data():\n",
    "    \"\"\"\n",
    "    Prepare enriched cluster data dengan tambahan informasi:\n",
    "    - Region mapping\n",
    "    - Cluster labels yang lebih deskriptif\n",
    "    - Category classification\n",
    "    \"\"\"\n",
    "\n",
    "    # Add cluster labels berdasarkan profil\n",
    "    cluster_labels = {\n",
    "        0: \"Low Expenditure\",\n",
    "        1: \"Balanced Expenditure\",\n",
    "        2: \"High Expenditure\",\n",
    "    }\n",
    "\n",
    "    # Enrich clustering results\n",
    "    df = clustering_results.copy()\n",
    "    df['Cluster_Label'] = df['Cluster'].map(cluster_labels)\n",
    "\n",
    "    # Add category based on expenditure levels\n",
    "    df['Cluster_Category'] = df['Cluster_Label']\n",
    "\n",
    "    return df\n",
    "\n",
    "# Process data\n",
    "enriched_data = prepare_cluster_data()\n",
    "\n",
    "print(\"✓ Data preparation complete!\")\n",
    "print(f\"\\nEnriched data shape: {enriched_data.shape}\")\n",
    "print(\"\\nNew columns added:\")\n",
    "print([col for col in enriched_data.columns if col not in clustering_results.columns])\n",
    "print(\"\\nSample enriched data:\")\n",
    "enriched_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22f8273",
   "metadata": {},
   "source": [
    "## 4. Generate Predictions for 2025\n",
    "\n",
    "Menggunakan Linear Regression untuk prediksi tren pengeluaran tahun 2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c30621dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Predictions generated for 2025!\n",
      "\n",
      "Total predictions: 0\n",
      "\n",
      "Sample predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_predictions_2025():\n",
    "    \"\"\"\n",
    "    Generate predictions untuk pengeluaran 2025 berdasarkan tren 2023-2024\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    # Group by Kabupaten_Kota untuk time series\n",
    "    for kabupaten in enriched_data['Kabupaten_Kota'].unique():\n",
    "        kab_data = enriched_data[enriched_data['Kabupaten_Kota'] == kabupaten].sort_values('Tahun')\n",
    "        \n",
    "        if len(kab_data) >= 2:  # Need at least 2 years for prediction\n",
    "            years = kab_data['Tahun'].values.reshape(-1, 1)\n",
    "            \n",
    "            # Predict Buah\n",
    "            if 'Total_Buah' in kab_data.columns:\n",
    "                buah_values = kab_data['Total_Buah'].values\n",
    "                model_buah = LinearRegression()\n",
    "                model_buah.fit(years, buah_values)\n",
    "                pred_buah_2025 = model_buah.predict([[2025]])[0]\n",
    "            else:\n",
    "                pred_buah_2025 = kab_data['Pengeluaran_Buah'].iloc[-1] * 1.05  # 5% growth assumption\n",
    "            \n",
    "            # Predict Sayur\n",
    "            if 'Total_Sayur' in kab_data.columns:\n",
    "                sayur_values = kab_data['Total_Sayur'].values\n",
    "                model_sayur = LinearRegression()\n",
    "                model_sayur.fit(years, sayur_values)\n",
    "                pred_sayur_2025 = model_sayur.predict([[2025]])[0]\n",
    "            else:\n",
    "                pred_sayur_2025 = kab_data['Pengeluaran_Sayur'].iloc[-1] * 1.05\n",
    "            \n",
    "            # Get latest cluster info\n",
    "            latest = kab_data.iloc[-1]\n",
    "            \n",
    "            predictions.append({\n",
    "                'Kabupaten_Kota': kabupaten,\n",
    "                'Region': latest.get('Region', 'Unknown'),\n",
    "                'Cluster': int(latest['Cluster']),\n",
    "                'Cluster_Label': latest['Cluster_Label'],\n",
    "                'Predicted_Buah_2025': float(pred_buah_2025),\n",
    "                'Predicted_Sayur_2025': float(pred_sayur_2025),\n",
    "                'Predicted_Total_2025': float(pred_buah_2025 + pred_sayur_2025),\n",
    "                'Current_Buah_2024': float(latest.get('Total_Buah', latest.get('Pengeluaran_Buah', 0))),\n",
    "                'Current_Sayur_2024': float(latest.get('Total_Sayur', latest.get('Pengeluaran_Sayur', 0))),\n",
    "                'Growth_Rate_Buah': float((pred_buah_2025 / latest.get('Total_Buah', latest.get('Pengeluaran_Buah', 1)) - 1) * 100),\n",
    "                'Growth_Rate_Sayur': float((pred_sayur_2025 / latest.get('Total_Sayur', latest.get('Pengeluaran_Sayur', 1)) - 1) * 100)\n",
    "            })\n",
    "    \n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "    return predictions_df\n",
    "\n",
    "# Generate predictions\n",
    "predictions_2025 = generate_predictions_2025()\n",
    "\n",
    "print(\"✓ Predictions generated for 2025!\")\n",
    "print(f\"\\nTotal predictions: {len(predictions_2025)}\")\n",
    "print(\"\\nSample predictions:\")\n",
    "predictions_2025.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08dfa92",
   "metadata": {},
   "source": [
    "## 5. Create Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c97f9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Summary statistics generated!\n",
      "\n",
      "Overview:\n",
      "{\n",
      "  \"total_kabupaten\": 514,\n",
      "  \"total_clusters\": 3,\n",
      "  \"years_covered\": [\n",
      "    2024\n",
      "  ],\n",
      "  \"total_data_points\": 514\n",
      "}\n",
      "\n",
      "Cluster Distribution:\n",
      "{\n",
      "  \"0\": 209,\n",
      "  \"1\": 298,\n",
      "  \"2\": 7\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def generate_summary_statistics():\n",
    "    \"\"\"\n",
    "    Generate comprehensive summary statistics untuk dashboard\n",
    "    \"\"\"\n",
    "    \n",
    "    stats = {\n",
    "        'overview': {\n",
    "            'total_kabupaten': int(enriched_data['Kabupaten_Kota'].nunique()),\n",
    "            'total_clusters': int(enriched_data['Cluster'].nunique()),\n",
    "            'years_covered': sorted(enriched_data['Tahun'].unique().tolist()),\n",
    "            'total_data_points': int(len(enriched_data))\n",
    "        },\n",
    "        'cluster_distribution': enriched_data.groupby('Cluster')['Kabupaten_Kota'].count().to_dict(),\n",
    "        'cluster_labels': enriched_data.groupby('Cluster')['Cluster_Label'].first().to_dict(),\n",
    "        'regional_distribution': enriched_data['Region'].value_counts().to_dict() if 'Region' in enriched_data.columns else {},\n",
    "        'expenditure_summary': {\n",
    "            'avg_buah': float(enriched_data.get('Total_Buah', enriched_data.get('Pengeluaran_Buah', pd.Series([0]))).mean()),\n",
    "            'avg_sayur': float(enriched_data.get('Total_Sayur', enriched_data.get('Pengeluaran_Sayur', pd.Series([0]))).mean()),\n",
    "            'max_buah': float(enriched_data.get('Total_Buah', enriched_data.get('Pengeluaran_Buah', pd.Series([0]))).max()),\n",
    "            'max_sayur': float(enriched_data.get('Total_Sayur', enriched_data.get('Pengeluaran_Sayur', pd.Series([0]))).max()),\n",
    "            'min_buah': float(enriched_data.get('Total_Buah', enriched_data.get('Pengeluaran_Buah', pd.Series([0]))).min()),\n",
    "            'min_sayur': float(enriched_data.get('Total_Sayur', enriched_data.get('Pengeluaran_Sayur', pd.Series([0]))).min())\n",
    "        },\n",
    "        'cluster_profiles': cluster_profiles.to_dict('records'),\n",
    "        'centroids': cluster_centroids.to_dict('records')\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Generate statistics\n",
    "summary_stats = generate_summary_statistics()\n",
    "\n",
    "print(\"✓ Summary statistics generated!\")\n",
    "print(\"\\nOverview:\")\n",
    "print(json.dumps(summary_stats['overview'], indent=2))\n",
    "print(\"\\nCluster Distribution:\")\n",
    "print(json.dumps(summary_stats['cluster_distribution'], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85145277",
   "metadata": {},
   "source": [
    "## 6. Export Data for Frontend\n",
    "\n",
    "Export processed data ke format yang mudah dikonsumsi oleh frontend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc2a9819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Exported: frontend\\public\\data\\modeling\\predictions_2025.csv\n",
      "✓ Exported: frontend\\public\\data\\modeling\\summary_statistics.json\n",
      "⚠ Warning: No predictions data available (need multi-year data for predictions)\n",
      "✓ Exported: frontend\\public\\data\\modeling\\visualization_data.json\n",
      "\n",
      "============================================================\n",
      "DATA EXPORT COMPLETE\n",
      "============================================================\n",
      "Files exported to: d:\\Perkuliahan\\2025-2026\\Analisa Big Data\\ProjectABD\\frontend\\public\\data\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "frontend_data_dir = Path('frontend/public/data')\n",
    "frontend_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create modeling subdirectory\n",
    "modeling_dir_output = frontend_data_dir / 'modeling'\n",
    "modeling_dir_output.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Export predictions\n",
    "predictions_2025.to_csv(modeling_dir_output / 'predictions_2025.csv', index=False)\n",
    "print(f\"✓ Exported: {modeling_dir_output / 'predictions_2025.csv'}\")\n",
    "\n",
    "# Export summary statistics as JSON\n",
    "with open(modeling_dir_output / 'summary_statistics.json', 'w') as f:\n",
    "    json.dump(summary_stats, f, indent=2)\n",
    "print(f\"✓ Exported: {modeling_dir_output / 'summary_statistics.json'}\")\n",
    "\n",
    "# Create visualization data for charts\n",
    "viz_data = {\n",
    "    'cluster_sizes': enriched_data.groupby(['Cluster', 'Cluster_Label']).size().reset_index(name='count').to_dict('records'),\n",
    "    'expenditure_by_cluster': enriched_data.groupby('Cluster').agg({\n",
    "        'Pengeluaran_Buah': 'mean',\n",
    "        'Pengeluaran_Sayur': 'mean'\n",
    "    }).reset_index().to_dict('records')\n",
    "}\n",
    "\n",
    "# Only add predictions summary if predictions exist\n",
    "if len(predictions_2025) > 0 and 'Cluster' in predictions_2025.columns:\n",
    "    viz_data['predictions_summary'] = predictions_2025.groupby('Cluster').agg({\n",
    "        'Predicted_Buah_2025': 'mean',\n",
    "        'Predicted_Sayur_2025': 'mean',\n",
    "        'Growth_Rate_Buah': 'mean',\n",
    "        'Growth_Rate_Sayur': 'mean'\n",
    "    }).reset_index().to_dict('records')\n",
    "else:\n",
    "    viz_data['predictions_summary'] = []\n",
    "    print(\"⚠ Warning: No predictions data available (need multi-year data for predictions)\")\n",
    "\n",
    "with open(modeling_dir_output / 'visualization_data.json', 'w') as f:\n",
    "    json.dump(viz_data, f, indent=2)\n",
    "print(f\"✓ Exported: {modeling_dir_output / 'visualization_data.json'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA EXPORT COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Files exported to: {frontend_data_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd8d993",
   "metadata": {},
   "source": [
    "## 7. Flask API Application\n",
    "\n",
    "Create REST API endpoints untuk frontend consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "518ef978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Flask API initialized successfully!\n",
      "\n",
      "Available endpoints:\n",
      "  GET  /api/health\n",
      "  GET  /api/clusters\n",
      "  GET  /api/clusters/<id>\n",
      "  GET  /api/statistics\n",
      "  GET  /api/predictions\n",
      "  GET  /api/regions\n",
      "  GET  /api/search\n",
      "  GET  /api/visualization\n"
     ]
    }
   ],
   "source": [
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable CORS for all routes\n",
    "\n",
    "# ============================================\n",
    "# API ENDPOINTS\n",
    "# ============================================\n",
    "\n",
    "@app.route('/api/health', methods=['GET'])\n",
    "def health_check():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return jsonify({\n",
    "        'status': 'healthy',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'version': '1.0.0'\n",
    "    })\n",
    "\n",
    "@app.route('/api/clusters', methods=['GET'])\n",
    "def get_all_clusters():\n",
    "    \"\"\"\n",
    "    Get all clustering data\n",
    "    Query params:\n",
    "    - year: Filter by year (2023, 2024)\n",
    "    - cluster: Filter by cluster ID\n",
    "    - region: Filter by region\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = enriched_data.copy()\n",
    "        \n",
    "        # Apply filters\n",
    "        if 'year' in request.args:\n",
    "            year = int(request.args.get('year'))\n",
    "            df = df[df['Tahun'] == year]\n",
    "        \n",
    "        if 'cluster' in request.args:\n",
    "            cluster = int(request.args.get('cluster'))\n",
    "            df = df[df['Cluster'] == cluster]\n",
    "        \n",
    "        if 'region' in request.args:\n",
    "            region = request.args.get('region')\n",
    "            if 'Region' in df.columns:\n",
    "                df = df[df['Region'] == region]\n",
    "        \n",
    "        # Convert to JSON-friendly format\n",
    "        result = df.to_dict('records')\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'count': len(result),\n",
    "            'data': result\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/clusters/<int:cluster_id>', methods=['GET'])\n",
    "def get_cluster_by_id(cluster_id):\n",
    "    \"\"\"\n",
    "    Get specific cluster data and profile\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get cluster data\n",
    "        cluster_data = enriched_data[enriched_data['Cluster'] == cluster_id]\n",
    "        \n",
    "        # Get cluster profile\n",
    "        profile = cluster_profiles[cluster_profiles['Cluster'] == cluster_id].to_dict('records')\n",
    "        \n",
    "        # Get centroid\n",
    "        centroid = cluster_centroids[cluster_centroids['Cluster'] == cluster_id].to_dict('records')\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'cluster_id': cluster_id,\n",
    "            'profile': profile[0] if profile else {},\n",
    "            'centroid': centroid[0] if centroid else {},\n",
    "            'data': cluster_data.to_dict('records'),\n",
    "            'count': len(cluster_data)\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/statistics', methods=['GET'])\n",
    "def get_statistics():\n",
    "    \"\"\"\n",
    "    Get summary statistics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'data': summary_stats\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/predictions', methods=['GET'])\n",
    "def get_predictions():\n",
    "    \"\"\"\n",
    "    Get predictions for 2025\n",
    "    Query params:\n",
    "    - cluster: Filter by cluster ID\n",
    "    - kabupaten: Search by kabupaten name\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = predictions_2025.copy()\n",
    "        \n",
    "        if 'cluster' in request.args:\n",
    "            cluster = int(request.args.get('cluster'))\n",
    "            df = df[df['Cluster'] == cluster]\n",
    "        \n",
    "        if 'kabupaten' in request.args:\n",
    "            kabupaten = request.args.get('kabupaten').lower()\n",
    "            df = df[df['Kabupaten_Kota'].str.lower().str.contains(kabupaten)]\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'count': len(df),\n",
    "            'data': df.to_dict('records')\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/regions', methods=['GET'])\n",
    "def get_regions():\n",
    "    \"\"\"\n",
    "    Get unique regions and their statistics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if 'Region' not in enriched_data.columns:\n",
    "            return jsonify({\n",
    "                'success': False,\n",
    "                'error': 'Region data not available'\n",
    "            }), 404\n",
    "        \n",
    "        regions = enriched_data.groupby('Region').agg({\n",
    "            'Kabupaten_Kota': 'count',\n",
    "            'Total_Buah': 'mean' if 'Total_Buah' in enriched_data.columns else lambda x: 0,\n",
    "            'Total_Sayur': 'mean' if 'Total_Sayur' in enriched_data.columns else lambda x: 0\n",
    "        }).reset_index()\n",
    "        \n",
    "        regions.columns = ['Region', 'Count', 'Avg_Buah', 'Avg_Sayur']\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'data': regions.to_dict('records')\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/search', methods=['GET'])\n",
    "def search_kabupaten():\n",
    "    \"\"\"\n",
    "    Search kabupaten/kota by name\n",
    "    Query params:\n",
    "    - q: Search query\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query = request.args.get('q', '').lower()\n",
    "        \n",
    "        if not query:\n",
    "            return jsonify({\n",
    "                'success': False,\n",
    "                'error': 'Query parameter q is required'\n",
    "            }), 400\n",
    "        \n",
    "        results = enriched_data[\n",
    "            enriched_data['Kabupaten_Kota'].str.lower().str.contains(query)\n",
    "        ]\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'query': query,\n",
    "            'count': len(results),\n",
    "            'data': results.to_dict('records')\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/visualization', methods=['GET'])\n",
    "def get_visualization_data():\n",
    "    \"\"\"\n",
    "    Get pre-processed data for visualizations\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'data': viz_data\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "print(\"✓ Flask API initialized successfully!\")\n",
    "print(\"\\nAvailable endpoints:\")\n",
    "print(\"  GET  /api/health\")\n",
    "print(\"  GET  /api/clusters\")\n",
    "print(\"  GET  /api/clusters/<id>\")\n",
    "print(\"  GET  /api/statistics\")\n",
    "print(\"  GET  /api/predictions\")\n",
    "print(\"  GET  /api/regions\")\n",
    "print(\"  GET  /api/search\")\n",
    "print(\"  GET  /api/visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753cbd8d",
   "metadata": {},
   "source": [
    "## 8. Save Flask App to Python File\n",
    "\n",
    "**Note**: Flask server tidak bisa dijalankan langsung di Jupyter notebook.\n",
    "Kita akan save Flask app ke file `api.py` yang bisa dijalankan di terminal.\n",
    "\n",
    "**Cara menjalankan**:\n",
    "\n",
    "**Option 1 - Jalankan di Jupyter Notebook/VS Code**:\n",
    "- Jalankan semua cell di notebook ini (cell 1-13)\n",
    "- File `api.py` akan otomatis dibuat\n",
    "- Lalu jalankan `api.py` di terminal\n",
    "\n",
    "**Option 2 - Langsung di terminal**:\n",
    "```powershell\n",
    "# Di terminal\n",
    "python api.py\n",
    "```\n",
    "\n",
    "**Option 3 - Production dengan Gunicorn**:\n",
    "```powershell\n",
    "pip install gunicorn\n",
    "gunicorn -w 4 -b 0.0.0.0:5000 api:app\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9061c539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Flask API saved to api.py\n",
      "\n",
      "============================================================\n",
      "TO RUN THE API SERVER:\n",
      "============================================================\n",
      "\n",
      "Option 1 - Development mode:\n",
      "  python api.py\n",
      "\n",
      "Option 2 - Production mode (install gunicorn first):\n",
      "  pip install gunicorn\n",
      "  gunicorn -w 4 -b 0.0.0.0:5000 api:app\n",
      "\n",
      "Option 3 - Run in background (Windows PowerShell):\n",
      "  Start-Process python -ArgumentList 'api.py' -WindowStyle Hidden\n",
      "\n",
      "============================================================\n",
      "\n",
      "API will be available at: http://localhost:5000/api\n",
      "Test with: http://localhost:5000/api/health\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "flask_code = ''''\n",
    "from flask import Flask, jsonify, request\n",
    "from flask_cors import CORS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load data\n",
    "DATA_DIR = Path(\"data/result\")\n",
    "CLEANED_DIR = Path(\"data/cleaned\")\n",
    "JSON_EXPORT_DIR = Path(\"data/api_exports\")\n",
    "\n",
    "# Load clustering results\n",
    "clustering_results = pd.read_csv(DATA_DIR / \"clustering_results.csv\")\n",
    "cluster_profiles = pd.read_csv(DATA_DIR / \"cluster_profiles.csv\")\n",
    "cluster_centroids = pd.read_csv(DATA_DIR / \"cluster_centroids.csv\")\n",
    "\n",
    "# Prepare enriched data with cluster labels\n",
    "cluster_labels_map = {\n",
    "    0: \"Low Expenditure\",\n",
    "    1: \"Balanced Expenditure\",\n",
    "    2: \"High Expenditure\",\n",
    "}\n",
    "enriched_data = clustering_results.copy()\n",
    "enriched_data[\"Cluster_Label\"] = enriched_data[\"Cluster\"].map(cluster_labels_map)\n",
    "\n",
    "# Load JSON exports\n",
    "try:\n",
    "    with open(JSON_EXPORT_DIR / \"all_clusters.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        all_clusters_json = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    all_clusters_json = {\"metadata\": {}, \"data\": []}\n",
    "\n",
    "try:\n",
    "    with open(JSON_EXPORT_DIR / \"cluster_details.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        cluster_details_json = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    cluster_details_json = {\"metadata\": {}, \"clusters\": []}\n",
    "\n",
    "try:\n",
    "    with open(JSON_EXPORT_DIR / \"predictions_full.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        predictions_json = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    predictions_json = {\"metadata\": {}, \"predictions\": []}\n",
    "\n",
    "try:\n",
    "    with open(JSON_EXPORT_DIR / \"regional_analysis.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        regional_json = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    regional_json = {\"metadata\": {}, \"regions\": []}\n",
    "\n",
    "try:\n",
    "    with open(JSON_EXPORT_DIR / \"expenditure_trends.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        trends_json = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    trends_json = {\"metadata\": {}, \"trends\": []}\n",
    "\n",
    "try:\n",
    "    with open(JSON_EXPORT_DIR / \"api_metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        api_metadata = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    api_metadata = {\"api_version\": \"1.0.0\", \"data_summary\": {}}\n",
    "\n",
    "# Generate summary statistics\n",
    "summary_stats = {\n",
    "    \"overview\": {\n",
    "        \"total_kabupaten\": int(enriched_data[\"Kabupaten_Kota\"].nunique()),\n",
    "        \"total_clusters\": int(enriched_data[\"Cluster\"].nunique()),\n",
    "        \"years_covered\": sorted(enriched_data[\"Tahun\"].unique().tolist()),\n",
    "        \"total_data_points\": int(len(enriched_data)),\n",
    "    },\n",
    "    \"cluster_distribution\": enriched_data.groupby(\"Cluster\")[\"Kabupaten_Kota\"]\n",
    "    .count()\n",
    "    .to_dict(),\n",
    "    \"cluster_labels\": enriched_data.groupby(\"Cluster\")[\"Cluster_Label\"]\n",
    "    .first()\n",
    "    .to_dict(),\n",
    "    \"regional_distribution\": (\n",
    "        enriched_data[\"Region\"].value_counts().to_dict()\n",
    "        if \"Region\" in enriched_data.columns\n",
    "        else {}\n",
    "    ),\n",
    "    \"expenditure_summary\": {\n",
    "        \"avg_buah\": float(enriched_data[\"Pengeluaran_Buah\"].mean()),\n",
    "        \"avg_sayur\": float(enriched_data[\"Pengeluaran_Sayur\"].mean()),\n",
    "        \"max_buah\": float(enriched_data[\"Pengeluaran_Buah\"].max()),\n",
    "        \"max_sayur\": float(enriched_data[\"Pengeluaran_Sayur\"].max()),\n",
    "        \"min_buah\": float(enriched_data[\"Pengeluaran_Buah\"].min()),\n",
    "        \"min_sayur\": float(enriched_data[\"Pengeluaran_Sayur\"].min()),\n",
    "    },\n",
    "    \"cluster_profiles\": cluster_profiles.to_dict(\"records\"),\n",
    "    \"centroids\": cluster_centroids.to_dict(\"records\"),\n",
    "}\n",
    "\n",
    "# Generate predictions for 2025 using Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "predictions_list = []\n",
    "for kabupaten in enriched_data[\"Kabupaten_Kota\"].unique():\n",
    "    kab_data = enriched_data[enriched_data[\"Kabupaten_Kota\"] == kabupaten].sort_values(\n",
    "        \"Tahun\"\n",
    "    )\n",
    "\n",
    "    if len(kab_data) >= 2:\n",
    "        years = kab_data[\"Tahun\"].values.reshape(-1, 1)\n",
    "\n",
    "        # Predict Buah\n",
    "        buah_values = kab_data[\"Pengeluaran_Buah\"].values\n",
    "        model_buah = LinearRegression()\n",
    "        model_buah.fit(years, buah_values)\n",
    "        pred_buah_2025 = model_buah.predict([[2025]])[0]\n",
    "\n",
    "        # Predict Sayur\n",
    "        sayur_values = kab_data[\"Pengeluaran_Sayur\"].values\n",
    "        model_sayur = LinearRegression()\n",
    "        model_sayur.fit(years, sayur_values)\n",
    "        pred_sayur_2025 = model_sayur.predict([[2025]])[0]\n",
    "\n",
    "        latest = kab_data.iloc[-1]\n",
    "\n",
    "        predictions_list.append(\n",
    "            {\n",
    "                \"Kabupaten_Kota\": kabupaten,\n",
    "                \"Region\": latest.get(\"Region\", \"Unknown\"),\n",
    "                \"Cluster\": int(latest[\"Cluster\"]),\n",
    "                \"Cluster_Label\": latest[\"Cluster_Label\"],\n",
    "                \"Predicted_Buah_2025\": float(pred_buah_2025),\n",
    "                \"Predicted_Sayur_2025\": float(pred_sayur_2025),\n",
    "                \"Predicted_Total_2025\": float(pred_buah_2025 + pred_sayur_2025),\n",
    "                \"Current_Buah_2024\": float(latest[\"Pengeluaran_Buah\"]),\n",
    "                \"Current_Sayur_2024\": float(latest[\"Pengeluaran_Sayur\"]),\n",
    "                \"Growth_Rate_Buah\": (\n",
    "                    float((pred_buah_2025 / latest[\"Pengeluaran_Buah\"] - 1) * 100)\n",
    "                    if latest[\"Pengeluaran_Buah\"] > 0\n",
    "                    else 0\n",
    "                ),\n",
    "                \"Growth_Rate_Sayur\": (\n",
    "                    float((pred_sayur_2025 / latest[\"Pengeluaran_Sayur\"] - 1) * 100)\n",
    "                    if latest[\"Pengeluaran_Sayur\"] > 0\n",
    "                    else 0\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "predictions_2025 = pd.DataFrame(predictions_list)\n",
    "\n",
    "# Create visualization data\n",
    "viz_data = {\n",
    "    \"cluster_sizes\": enriched_data.groupby([\"Cluster\", \"Cluster_Label\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .to_dict(\"records\"),\n",
    "    \"expenditure_by_cluster\": enriched_data.groupby(\"Cluster\")\n",
    "    .agg({\"Pengeluaran_Buah\": \"mean\", \"Pengeluaran_Sayur\": \"mean\"})\n",
    "    .reset_index()\n",
    "    .to_dict(\"records\"),\n",
    "}\n",
    "\n",
    "if len(predictions_2025) > 0:\n",
    "    viz_data[\"predictions_summary\"] = (\n",
    "        predictions_2025.groupby(\"Cluster\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"Predicted_Buah_2025\": \"mean\",\n",
    "                \"Predicted_Sayur_2025\": \"mean\",\n",
    "                \"Growth_Rate_Buah\": \"mean\",\n",
    "                \"Growth_Rate_Sayur\": \"mean\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "        .to_dict(\"records\")\n",
    "    )\n",
    "else:\n",
    "    viz_data[\"predictions_summary\"] = []\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "\n",
    "@app.route(\"/api/health\", methods=[\"GET\"])\n",
    "def health_check():\n",
    "    return jsonify(\n",
    "        {\n",
    "            \"status\": \"healthy\",\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"version\": \"1.0.0\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "@app.route(\"/api/clusters\", methods=[\"GET\"])\n",
    "def get_all_clusters():\n",
    "    try:\n",
    "        df = enriched_data.copy()\n",
    "\n",
    "        if \"year\" in request.args:\n",
    "            year = int(request.args.get(\"year\"))\n",
    "            df = df[df[\"Tahun\"] == year]\n",
    "\n",
    "        if \"cluster\" in request.args:\n",
    "            cluster = int(request.args.get(\"cluster\"))\n",
    "            df = df[df[\"Cluster\"] == cluster]\n",
    "\n",
    "        if \"region\" in request.args:\n",
    "            region = request.args.get(\"region\")\n",
    "            if \"Region\" in df.columns:\n",
    "                df = df[df[\"Region\"] == region]\n",
    "\n",
    "        result = df.to_dict(\"records\")\n",
    "\n",
    "        return jsonify({\"success\": True, \"count\": len(result), \"data\": result})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"success\": False, \"error\": str(e)}), 500\n",
    "\n",
    "\n",
    "@app.route(\"/api/clusters/<int:cluster_id>\", methods=[\"GET\"])\n",
    "def get_cluster_by_id(cluster_id):\n",
    "    try:\n",
    "        cluster_data = enriched_data[enriched_data[\"Cluster\"] == cluster_id]\n",
    "        profile = cluster_profiles[cluster_profiles[\"Cluster\"] == cluster_id].to_dict(\n",
    "            \"records\"\n",
    "        )\n",
    "        centroid = cluster_centroids[\n",
    "            cluster_centroids[\"Cluster\"] == cluster_id\n",
    "        ].to_dict(\"records\")\n",
    "\n",
    "        return jsonify(\n",
    "            {\n",
    "                \"success\": True,\n",
    "                \"cluster_id\": cluster_id,\n",
    "                \"profile\": profile[0] if profile else {},\n",
    "                \"centroid\": centroid[0] if centroid else {},\n",
    "                \"data\": cluster_data.to_dict(\"records\"),\n",
    "                \"count\": len(cluster_data),\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return jsonify({\"success\": False, \"error\": str(e)}), 500\n",
    "\n",
    "\n",
    "@app.route(\"/api/statistics\", methods=[\"GET\"])\n",
    "def get_statistics():\n",
    "    try:\n",
    "        return jsonify({\"success\": True, \"data\": summary_stats})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"success\": False, \"error\": str(e)}), 500\n",
    "\n",
    "\n",
    "@app.route(\"/api/predictions\", methods=[\"GET\"])\n",
    "def get_predictions():\n",
    "    try:\n",
    "        df = predictions_2025.copy()\n",
    "\n",
    "        if \"cluster\" in request.args and len(df) > 0:\n",
    "            cluster = int(request.args.get(\"cluster\"))\n",
    "            df = df[df[\"Cluster\"] == cluster]\n",
    "\n",
    "        if \"kabupaten\" in request.args and len(df) > 0:\n",
    "            kabupaten = request.args.get(\"kabupaten\").lower()\n",
    "            df = df[df[\"Kabupaten_Kota\"].str.lower().str.contains(kabupaten)]\n",
    "\n",
    "        return jsonify(\n",
    "            {\"success\": True, \"count\": len(df), \"data\": df.to_dict(\"records\")}\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return jsonify({\"success\": False, \"error\": str(e)}), 500\n",
    "\n",
    "\n",
    "@app.route(\"/api/regions\", methods=[\"GET\"])\n",
    "def get_regions():\n",
    "    try:\n",
    "        if \"Region\" not in enriched_data.columns:\n",
    "            return (\n",
    "                jsonify({\"success\": False, \"error\": \"Region data not available\"}),\n",
    "                404,\n",
    "            )\n",
    "\n",
    "        # Use Pengeluaran_Buah and Pengeluaran_Sayur instead of Total_Buah and Total_Sayur\n",
    "        regions = (\n",
    "            enriched_data.groupby(\"Region\")\n",
    "            .agg(\n",
    "                {\n",
    "                    \"Kabupaten_Kota\": \"count\",\n",
    "                    \"Pengeluaran_Buah\": \"mean\",\n",
    "                    \"Pengeluaran_Sayur\": \"mean\",\n",
    "                }\n",
    "            )\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        regions.columns = [\"Region\", \"Count\", \"Avg_Buah\", \"Avg_Sayur\"]\n",
    "\n",
    "        return jsonify({\"success\": True, \"data\": regions.to_dict(\"records\")})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"success\": False, \"error\": str(e)}), 500\n",
    "\n",
    "\n",
    "@app.route(\"/api/regions/list\", methods=[\"GET\"])\n",
    "def get_regions_list():\n",
    "    \"\"\"Get unique list of regions/provinces\"\"\"\n",
    "    try:\n",
    "        if \"Region\" not in enriched_data.columns:\n",
    "            return (\n",
    "                jsonify({\"success\": False, \"error\": \"Region data not available\"}),\n",
    "                404,\n",
    "            )\n",
    "\n",
    "        # Get unique regions sorted alphabetically\n",
    "        regions_list = sorted(enriched_data[\"Region\"].dropna().unique().tolist())\n",
    "\n",
    "        return jsonify(\n",
    "            {\"success\": True, \"count\": len(regions_list), \"data\": regions_list}\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return jsonify({\"success\": False, \"error\": str(e)}), 500\n",
    "\n",
    "\n",
    "@app.route(\"/api/search\", methods=[\"GET\"])\n",
    "def search_kabupaten():\n",
    "    try:\n",
    "        query = request.args.get(\"q\", \"\").lower()\n",
    "\n",
    "        if not query:\n",
    "            return (\n",
    "                jsonify({\"success\": False, \"error\": \"Query parameter q is required\"}),\n",
    "                400,\n",
    "            )\n",
    "\n",
    "        results = enriched_data[\n",
    "            enriched_data[\"Kabupaten_Kota\"].str.lower().str.contains(query)\n",
    "        ]\n",
    "\n",
    "        return jsonify(\n",
    "            {\n",
    "                \"success\": True,\n",
    "                \"query\": query,\n",
    "                \"count\": len(results),\n",
    "                \"data\": results.to_dict(\"records\"),\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return jsonify({\"success\": False, \"error\": str(e)}), 500\n",
    "\n",
    "\n",
    "@app.route(\"/api/visualization\", methods=[\"GET\"])\n",
    "def get_visualization_data():\n",
    "    try:\n",
    "        return jsonify({\"success\": True, \"data\": viz_data})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"success\": False, \"error\": str(e)}), 500\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"STARTING FLASK API SERVER\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Server Configuration:\")\n",
    "    print(\"  Host: 0.0.0.0\")\n",
    "    print(\"  Port: 5000\")\n",
    "    print(\"  Debug: True\")\n",
    "    print(\"  CORS: Enabled\")\n",
    "    print(\"API Base URL: http://localhost:5000/api\")\n",
    "    print(\"Press CTRL+C to stop the server\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    app.run(host=\"0.0.0.0\", port=5000, debug=True)\n",
    "\n",
    "'''\n",
    "# Write to file\n",
    "with open('api.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(flask_code)\n",
    "\n",
    "print(\"✓ Flask API saved to api.py\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TO RUN THE API SERVER:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nOption 1 - Development mode:\")\n",
    "print(\"  python api.py\")\n",
    "print(\"\\nOption 2 - Production mode (install gunicorn first):\")\n",
    "print(\"  pip install gunicorn\")\n",
    "print(\"  gunicorn -w 4 -b 0.0.0.0:5000 api:app\")\n",
    "print(\"\\nOption 3 - Run in background (Windows PowerShell):\")\n",
    "print(\"  Start-Process python -ArgumentList 'api.py' -WindowStyle Hidden\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nAPI will be available at: http://localhost:5000/api\")\n",
    "print(\"Test with: http://localhost:5000/api/health\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f2a464",
   "metadata": {},
   "source": [
    "## 9. API Testing & Examples\n",
    "\n",
    "Test API endpoints menggunakan requests library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a83573a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "API ENDPOINT TESTING\n",
      "============================================================\n",
      "\n",
      "1. Testing /api/health...\n",
      "   Status: 200\n",
      "   Response: {'status': 'healthy', 'timestamp': '2025-11-29T12:39:05.967392', 'version': '1.0.0'}\n",
      "\n",
      "2. Testing /api/statistics...\n",
      "   Status: 200\n",
      "   Total Kabupaten: 514\n",
      "   Total Clusters: 3\n",
      "\n",
      "3. Testing /api/clusters...\n",
      "   Status: 200\n",
      "   Data count: 514\n",
      "   Sample: {'Cluster': 0, 'Cluster_Label': 'Low Expenditure', 'Kabupaten_Kota': 'Aceh Barat', 'Pengeluaran_Buah': 11160.0, 'Pengeluaran_Sayur': 15821.0, 'Region': 'Aceh', 'Tahun': 2024}\n",
      "\n",
      "4. Testing /api/clusters/0...\n",
      "   Status: 200\n",
      "   Cluster ID: 0\n",
      "   Data count: 209\n",
      "   Profile: {'Centroid_Buah': 12265.885167464114, 'Centroid_Sayur': 15813.181818181818, 'Cluster': 0, 'Mean_Buah': 12265.885167464116, 'Mean_Sayur': 15813.181818181818, 'Median_Buah': 11793.0, 'Median_Sayur': 15504.0, 'Silhouette_Score': 0.3697304324345739, 'Size': 209, 'Std_Buah': 2167.8291596886147, 'Std_Sayur': 4077.841028923005}\n",
      "\n",
      "5. Testing /api/predictions...\n",
      "   Status: 200\n",
      "   Predictions count: 0\n",
      "\n",
      "6. Testing /api/search?q=jakarta...\n",
      "   Status: 200\n",
      "   Results found: 5\n",
      "   First result: Kota Jakarta Barat\n",
      "\n",
      "============================================================\n",
      "✓ API Testing Complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "BASE_URL = 'http://localhost:5000/api'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"API ENDPOINT TESTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test 1: Health Check\n",
    "print(\"\\n1. Testing /api/health...\")\n",
    "try:\n",
    "    response = requests.get(f'{BASE_URL}/health')\n",
    "    print(f\"   Status: {response.status_code}\")\n",
    "    print(f\"   Response: {response.json()}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "# Test 2: Get Statistics\n",
    "print(\"\\n2. Testing /api/statistics...\")\n",
    "try:\n",
    "    response = requests.get(f'{BASE_URL}/statistics')\n",
    "    print(f\"   Status: {response.status_code}\")\n",
    "    data = response.json()\n",
    "    if data['success']:\n",
    "        print(f\"   Total Kabupaten: {data['data']['overview']['total_kabupaten']}\")\n",
    "        print(f\"   Total Clusters: {data['data']['overview']['total_clusters']}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "# Test 3: Get All Clusters\n",
    "print(\"\\n3. Testing /api/clusters...\")\n",
    "try:\n",
    "    response = requests.get(f'{BASE_URL}/clusters?year=2024')\n",
    "    print(f\"   Status: {response.status_code}\")\n",
    "    data = response.json()\n",
    "    if data['success']:\n",
    "        print(f\"   Data count: {data['count']}\")\n",
    "        print(f\"   Sample: {data['data'][0] if data['data'] else 'No data'}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "# Test 4: Get Specific Cluster\n",
    "print(\"\\n4. Testing /api/clusters/0...\")\n",
    "try:\n",
    "    response = requests.get(f'{BASE_URL}/clusters/0')\n",
    "    print(f\"   Status: {response.status_code}\")\n",
    "    data = response.json()\n",
    "    if data['success']:\n",
    "        print(f\"   Cluster ID: {data['cluster_id']}\")\n",
    "        print(f\"   Data count: {data['count']}\")\n",
    "        print(f\"   Profile: {data['profile']}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "# Test 5: Get Predictions\n",
    "print(\"\\n5. Testing /api/predictions...\")\n",
    "try:\n",
    "    response = requests.get(f'{BASE_URL}/predictions?cluster=0')\n",
    "    print(f\"   Status: {response.status_code}\")\n",
    "    data = response.json()\n",
    "    if data['success']:\n",
    "        print(f\"   Predictions count: {data['count']}\")\n",
    "        if data['data']:\n",
    "            sample = data['data'][0]\n",
    "            print(f\"   Sample prediction for {sample['Kabupaten_Kota']}:\")\n",
    "            print(f\"     Predicted Buah 2025: Rp {sample['Predicted_Buah_2025']:,.0f}\")\n",
    "            print(f\"     Growth Rate: {sample['Growth_Rate_Buah']:.2f}%\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "# Test 6: Search\n",
    "print(\"\\n6. Testing /api/search?q=jakarta...\")\n",
    "try:\n",
    "    response = requests.get(f'{BASE_URL}/search?q=jakarta')\n",
    "    print(f\"   Status: {response.status_code}\")\n",
    "    data = response.json()\n",
    "    if data['success']:\n",
    "        print(f\"   Results found: {data['count']}\")\n",
    "        if data['data']:\n",
    "            print(f\"   First result: {data['data'][0]['Kabupaten_Kota']}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ API Testing Complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d16670",
   "metadata": {},
   "source": [
    "## 10. Integration Guide for Frontend\n",
    "\n",
    "### React/TypeScript Integration Example\n",
    "\n",
    "```typescript\n",
    "// services/apiService.ts\n",
    "const API_BASE_URL = 'http://localhost:5000/api';\n",
    "\n",
    "export const apiService = {\n",
    "  // Get all clusters\n",
    "  getClusters: async (filters?: { year?: number; cluster?: number }) => {\n",
    "    const params = new URLSearchParams(filters as any);\n",
    "    const response = await fetch(`${API_BASE_URL}/clusters?${params}`);\n",
    "    return response.json();\n",
    "  },\n",
    "\n",
    "  // Get specific cluster\n",
    "  getClusterById: async (id: number) => {\n",
    "    const response = await fetch(`${API_BASE_URL}/clusters/${id}`);\n",
    "    return response.json();\n",
    "  },\n",
    "\n",
    "  // Get statistics\n",
    "  getStatistics: async () => {\n",
    "    const response = await fetch(`${API_BASE_URL}/statistics`);\n",
    "    return response.json();\n",
    "  },\n",
    "\n",
    "  // Get predictions\n",
    "  getPredictions: async (cluster?: number) => {\n",
    "    const params = cluster ? `?cluster=${cluster}` : '';\n",
    "    const response = await fetch(`${API_BASE_URL}/predictions${params}`);\n",
    "    return response.json();\n",
    "  },\n",
    "\n",
    "  // Search kabupaten\n",
    "  searchKabupaten: async (query: string) => {\n",
    "    const response = await fetch(`${API_BASE_URL}/search?q=${encodeURIComponent(query)}`);\n",
    "    return response.json();\n",
    "  }\n",
    "};\n",
    "```\n",
    "\n",
    "### Usage in React Components\n",
    "\n",
    "```typescript\n",
    "// components/ClusterDashboard.tsx\n",
    "import { useEffect, useState } from 'react';\n",
    "import { apiService } from '../services/apiService';\n",
    "\n",
    "function ClusterDashboard() {\n",
    "  const [statistics, setStatistics] = useState(null);\n",
    "  const [loading, setLoading] = useState(true);\n",
    "\n",
    "  useEffect(() => {\n",
    "    const fetchData = async () => {\n",
    "      try {\n",
    "        const stats = await apiService.getStatistics();\n",
    "        if (stats.success) {\n",
    "          setStatistics(stats.data);\n",
    "        }\n",
    "      } catch (error) {\n",
    "        console.error('Error fetching statistics:', error);\n",
    "      } finally {\n",
    "        setLoading(false);\n",
    "      }\n",
    "    };\n",
    "\n",
    "    fetchData();\n",
    "  }, []);\n",
    "\n",
    "  if (loading) return <div>Loading...</div>;\n",
    "\n",
    "  return (\n",
    "    <div>\n",
    "      <h1>Cluster Analysis Dashboard</h1>\n",
    "      <p>Total Kabupaten: {statistics?.overview.total_kabupaten}</p>\n",
    "      <p>Total Clusters: {statistics?.overview.total_clusters}</p>\n",
    "    </div>\n",
    "  );\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb10086",
   "metadata": {},
   "source": [
    "## 11. Batch Export All JSON Files\n",
    "\n",
    "Program untuk mengekspor semua data ke format JSON yang dapat dikonsumsi oleh API atau aplikasi lain.\n",
    "\n",
    "**File yang akan dibuat**:\n",
    "1. `all_clusters.json` - Semua data clustering\n",
    "2. `cluster_details.json` - Detail per cluster dengan profil dan centroid\n",
    "3. `predictions_full.json` - Prediksi lengkap untuk 2025\n",
    "4. `regional_analysis.json` - Analisis per region\n",
    "5. `expenditure_trends.json` - Tren pengeluaran dari 2023-2024\n",
    "6. `api_metadata.json` - Metadata untuk dokumentasi API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "360b45b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BATCH JSON EXPORT - STARTED\n",
      "============================================================\n",
      "\n",
      "Export directory: d:\\Perkuliahan\\2025-2026\\Analisa Big Data\\ProjectABD\\data\\api_exports\n",
      "\n",
      "1. Exporting all_clusters.json...\n",
      "   ✓ Exported: 514 records\n",
      "\n",
      "2. Exporting cluster_details.json...\n",
      "   ✓ Exported: 3 cluster profiles\n",
      "\n",
      "3. Exporting predictions_full.json...\n",
      "   ⚠ No predictions available (multi-year data required)\n",
      "\n",
      "4. Exporting regional_analysis.json...\n",
      "   ✓ Exported: 35 regional profiles\n",
      "\n",
      "5. Exporting expenditure_trends.json...\n",
      "   ✓ Exported: 0 trend records\n",
      "\n",
      "6. Exporting api_metadata.json...\n",
      "   ✓ Exported: API metadata and documentation\n",
      "\n",
      "============================================================\n",
      "BATCH JSON EXPORT - COMPLETED\n",
      "============================================================\n",
      "\n",
      "Export Directory: d:\\Perkuliahan\\2025-2026\\Analisa Big Data\\ProjectABD\\data\\api_exports\n",
      "\n",
      "Files created:\n",
      "  1. all_clusters.json         - 514 records\n",
      "  2. cluster_details.json      - 3 clusters\n",
      "  3. predictions_full.json     - 0 predictions\n",
      "  4. regional_analysis.json    - 35 regions\n",
      "  5. expenditure_trends.json   - 0 trends\n",
      "  6. api_metadata.json         - API documentation\n",
      "\n",
      "Total size: 177.73 KB (0.17 MB)\n",
      "============================================================\n",
      "\n",
      "✓ All JSON files ready for API consumption!\n",
      "✓ Files can be served statically or loaded by backend API\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Create JSON export directory\n",
    "json_export_dir = Path('data/api_exports')\n",
    "json_export_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BATCH JSON EXPORT - STARTED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nExport directory: {json_export_dir.absolute()}\\n\")\n",
    "\n",
    "# ============================================\n",
    "# 1. ALL CLUSTERS DATA\n",
    "# ============================================\n",
    "print(\"1. Exporting all_clusters.json...\")\n",
    "all_clusters_data = {\n",
    "    'metadata': {\n",
    "        'total_records': len(enriched_data),\n",
    "        'total_kabupaten': enriched_data['Kabupaten_Kota'].nunique(),\n",
    "        'years': sorted(enriched_data['Tahun'].unique().tolist()),\n",
    "        'clusters': sorted(enriched_data['Cluster'].unique().tolist()),\n",
    "        'generated_at': datetime.now().isoformat()\n",
    "    },\n",
    "    'data': enriched_data.to_dict('records')\n",
    "}\n",
    "\n",
    "with open(json_export_dir / 'all_clusters.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_clusters_data, f, indent=2, ensure_ascii=False)\n",
    "print(f\"   ✓ Exported: {len(all_clusters_data['data'])} records\")\n",
    "\n",
    "# ============================================\n",
    "# 2. CLUSTER DETAILS (per cluster with profile & centroid)\n",
    "# ============================================\n",
    "print(\"\\n2. Exporting cluster_details.json...\")\n",
    "cluster_details = []\n",
    "\n",
    "for cluster_id in sorted(enriched_data['Cluster'].unique()):\n",
    "    # Get cluster data\n",
    "    cluster_data = enriched_data[enriched_data['Cluster'] == cluster_id]\n",
    "    \n",
    "    # Get profile\n",
    "    profile = cluster_profiles[cluster_profiles['Cluster'] == cluster_id].to_dict('records')\n",
    "    profile_data = profile[0] if profile else {}\n",
    "    \n",
    "    # Get centroid\n",
    "    centroid = cluster_centroids[cluster_centroids['Cluster'] == cluster_id].to_dict('records')\n",
    "    centroid_data = centroid[0] if centroid else {}\n",
    "    \n",
    "    # Get regional distribution\n",
    "    regional_dist = {}\n",
    "    if 'Region' in cluster_data.columns:\n",
    "        regional_dist = cluster_data['Region'].value_counts().to_dict()\n",
    "    \n",
    "    cluster_details.append({\n",
    "        'cluster_id': int(cluster_id),\n",
    "        'cluster_label': cluster_data['Cluster_Label'].iloc[0] if 'Cluster_Label' in cluster_data.columns else f\"Cluster {cluster_id}\",\n",
    "        'size': len(cluster_data),\n",
    "        'percentage': round((len(cluster_data) / len(enriched_data)) * 100, 2),\n",
    "        'profile': profile_data,\n",
    "        'centroid': centroid_data,\n",
    "        'regional_distribution': regional_dist,\n",
    "        'sample_kabupaten': cluster_data['Kabupaten_Kota'].head(10).tolist(),\n",
    "        'statistics': {\n",
    "            'avg_buah': float(cluster_data['Pengeluaran_Buah'].mean()),\n",
    "            'avg_sayur': float(cluster_data['Pengeluaran_Sayur'].mean()),\n",
    "            'median_buah': float(cluster_data['Pengeluaran_Buah'].median()),\n",
    "            'median_sayur': float(cluster_data['Pengeluaran_Sayur'].median()),\n",
    "            'std_buah': float(cluster_data['Pengeluaran_Buah'].std()),\n",
    "            'std_sayur': float(cluster_data['Pengeluaran_Sayur'].std())\n",
    "        }\n",
    "    })\n",
    "\n",
    "cluster_details_output = {\n",
    "    'metadata': {\n",
    "        'total_clusters': len(cluster_details),\n",
    "        'generated_at': datetime.now().isoformat()\n",
    "    },\n",
    "    'clusters': cluster_details\n",
    "}\n",
    "\n",
    "with open(json_export_dir / 'cluster_details.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(cluster_details_output, f, indent=2, ensure_ascii=False)\n",
    "print(f\"   ✓ Exported: {len(cluster_details)} cluster profiles\")\n",
    "\n",
    "# ============================================\n",
    "# 3. PREDICTIONS FULL\n",
    "# ============================================\n",
    "print(\"\\n3. Exporting predictions_full.json...\")\n",
    "if len(predictions_2025) > 0:\n",
    "    predictions_output = {\n",
    "        'metadata': {\n",
    "            'total_predictions': len(predictions_2025),\n",
    "            'prediction_year': 2025,\n",
    "            'base_years': [2023, 2024],\n",
    "            'generated_at': datetime.now().isoformat()\n",
    "        },\n",
    "        'predictions': predictions_2025.to_dict('records'),\n",
    "        'summary_by_cluster': predictions_2025.groupby('Cluster').agg({\n",
    "            'Predicted_Buah_2025': 'mean',\n",
    "            'Predicted_Sayur_2025': 'mean',\n",
    "            'Growth_Rate_Buah': 'mean',\n",
    "            'Growth_Rate_Sayur': 'mean'\n",
    "        }).reset_index().to_dict('records')\n",
    "    }\n",
    "    \n",
    "    with open(json_export_dir / 'predictions_full.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(predictions_output, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"   ✓ Exported: {len(predictions_2025)} predictions\")\n",
    "else:\n",
    "    print(\"   ⚠ No predictions available (multi-year data required)\")\n",
    "    # Create empty structure\n",
    "    predictions_output = {\n",
    "        'metadata': {\n",
    "            'total_predictions': 0,\n",
    "            'prediction_year': 2025,\n",
    "            'generated_at': datetime.now().isoformat(),\n",
    "            'note': 'No predictions available - multi-year data required'\n",
    "        },\n",
    "        'predictions': [],\n",
    "        'summary_by_cluster': []\n",
    "    }\n",
    "    with open(json_export_dir / 'predictions_full.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(predictions_output, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# ============================================\n",
    "# 4. REGIONAL ANALYSIS\n",
    "# ============================================\n",
    "print(\"\\n4. Exporting regional_analysis.json...\")\n",
    "regional_analysis = []\n",
    "\n",
    "if 'Region' in enriched_data.columns:\n",
    "    for region in sorted(enriched_data['Region'].unique()):\n",
    "        region_data = enriched_data[enriched_data['Region'] == region]\n",
    "        \n",
    "        # Cluster distribution in this region\n",
    "        cluster_dist = region_data['Cluster'].value_counts().to_dict()\n",
    "        \n",
    "        regional_analysis.append({\n",
    "            'region': region,\n",
    "            'total_kabupaten': len(region_data),\n",
    "            'percentage': round((len(region_data) / len(enriched_data)) * 100, 2),\n",
    "            'cluster_distribution': cluster_dist,\n",
    "            'expenditure': {\n",
    "                'avg_buah': float(region_data['Pengeluaran_Buah'].mean()),\n",
    "                'avg_sayur': float(region_data['Pengeluaran_Sayur'].mean()),\n",
    "                'total_avg': float(region_data['Pengeluaran_Buah'].mean() + region_data['Pengeluaran_Sayur'].mean()),\n",
    "                'max_buah': float(region_data['Pengeluaran_Buah'].max()),\n",
    "                'max_sayur': float(region_data['Pengeluaran_Sayur'].max()),\n",
    "                'min_buah': float(region_data['Pengeluaran_Buah'].min()),\n",
    "                'min_sayur': float(region_data['Pengeluaran_Sayur'].min())\n",
    "            },\n",
    "            'top_kabupaten': region_data.nlargest(5, 'Pengeluaran_Buah')['Kabupaten_Kota'].tolist()\n",
    "        })\n",
    "    \n",
    "    regional_output = {\n",
    "        'metadata': {\n",
    "            'total_regions': len(regional_analysis),\n",
    "            'generated_at': datetime.now().isoformat()\n",
    "        },\n",
    "        'regions': regional_analysis\n",
    "    }\n",
    "    \n",
    "    with open(json_export_dir / 'regional_analysis.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(regional_output, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"   ✓ Exported: {len(regional_analysis)} regional profiles\")\n",
    "else:\n",
    "    print(\"   ⚠ Region data not available\")\n",
    "\n",
    "# ============================================\n",
    "# 5. EXPENDITURE TRENDS (2023-2024)\n",
    "# ============================================\n",
    "print(\"\\n5. Exporting expenditure_trends.json...\")\n",
    "trends_data = []\n",
    "\n",
    "# Get data for each kabupaten across years\n",
    "for kabupaten in enriched_data['Kabupaten_Kota'].unique():\n",
    "    kab_data = enriched_data[enriched_data['Kabupaten_Kota'] == kabupaten].sort_values('Tahun')\n",
    "    \n",
    "    if len(kab_data) >= 2:  # Has data for both years\n",
    "        data_2023 = kab_data[kab_data['Tahun'] == 2023].iloc[0] if len(kab_data[kab_data['Tahun'] == 2023]) > 0 else None\n",
    "        data_2024 = kab_data[kab_data['Tahun'] == 2024].iloc[0] if len(kab_data[kab_data['Tahun'] == 2024]) > 0 else None\n",
    "        \n",
    "        if data_2023 is not None and data_2024 is not None:\n",
    "            # Calculate growth\n",
    "            growth_buah = ((data_2024['Pengeluaran_Buah'] - data_2023['Pengeluaran_Buah']) / data_2023['Pengeluaran_Buah']) * 100 if data_2023['Pengeluaran_Buah'] > 0 else 0\n",
    "            growth_sayur = ((data_2024['Pengeluaran_Sayur'] - data_2023['Pengeluaran_Sayur']) / data_2023['Pengeluaran_Sayur']) * 100 if data_2023['Pengeluaran_Sayur'] > 0 else 0\n",
    "            \n",
    "            trends_data.append({\n",
    "                'kabupaten': kabupaten,\n",
    "                'region': data_2024.get('Region', 'Unknown'),\n",
    "                'cluster': int(data_2024['Cluster']),\n",
    "                'year_2023': {\n",
    "                    'buah': float(data_2023['Pengeluaran_Buah']),\n",
    "                    'sayur': float(data_2023['Pengeluaran_Sayur']),\n",
    "                    'total': float(data_2023['Pengeluaran_Buah'] + data_2023['Pengeluaran_Sayur'])\n",
    "                },\n",
    "                'year_2024': {\n",
    "                    'buah': float(data_2024['Pengeluaran_Buah']),\n",
    "                    'sayur': float(data_2024['Pengeluaran_Sayur']),\n",
    "                    'total': float(data_2024['Pengeluaran_Buah'] + data_2024['Pengeluaran_Sayur'])\n",
    "                },\n",
    "                'growth': {\n",
    "                    'buah_percent': round(float(growth_buah), 2),\n",
    "                    'sayur_percent': round(float(growth_sayur), 2),\n",
    "                    'buah_absolute': float(data_2024['Pengeluaran_Buah'] - data_2023['Pengeluaran_Buah']),\n",
    "                    'sayur_absolute': float(data_2024['Pengeluaran_Sayur'] - data_2023['Pengeluaran_Sayur'])\n",
    "                }\n",
    "            })\n",
    "\n",
    "trends_output = {\n",
    "    'metadata': {\n",
    "        'total_kabupaten': len(trends_data),\n",
    "        'years': [2023, 2024],\n",
    "        'generated_at': datetime.now().isoformat()\n",
    "    },\n",
    "    'trends': trends_data\n",
    "}\n",
    "\n",
    "with open(json_export_dir / 'expenditure_trends.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(trends_output, f, indent=2, ensure_ascii=False)\n",
    "print(f\"   ✓ Exported: {len(trends_data)} trend records\")\n",
    "\n",
    "# ============================================\n",
    "# 6. API METADATA\n",
    "# ============================================\n",
    "print(\"\\n6. Exporting api_metadata.json...\")\n",
    "api_metadata = {\n",
    "    'api_version': '1.0.0',\n",
    "    'generated_at': datetime.now().isoformat(),\n",
    "    'data_summary': {\n",
    "        'total_kabupaten': int(enriched_data['Kabupaten_Kota'].nunique()),\n",
    "        'total_clusters': int(enriched_data['Cluster'].nunique()),\n",
    "        'total_regions': int(enriched_data['Region'].nunique()) if 'Region' in enriched_data.columns else 0,\n",
    "        'years_available': sorted(enriched_data['Tahun'].unique().tolist()),\n",
    "        'total_records': len(enriched_data)\n",
    "    },\n",
    "    'files': {\n",
    "        'all_clusters.json': {\n",
    "            'description': 'Complete clustering dataset with all kabupaten/kota',\n",
    "            'records': len(enriched_data),\n",
    "            'size_kb': round((json_export_dir / 'all_clusters.json').stat().st_size / 1024, 2)\n",
    "        },\n",
    "        'cluster_details.json': {\n",
    "            'description': 'Detailed profile for each cluster including statistics and samples',\n",
    "            'clusters': len(cluster_details),\n",
    "            'size_kb': round((json_export_dir / 'cluster_details.json').stat().st_size / 1024, 2)\n",
    "        },\n",
    "        'predictions_full.json': {\n",
    "            'description': 'Predictions for 2025 based on 2023-2024 trends',\n",
    "            'predictions': len(predictions_2025) if len(predictions_2025) > 0 else 0,\n",
    "            'size_kb': round((json_export_dir / 'predictions_full.json').stat().st_size / 1024, 2)\n",
    "        },\n",
    "        'regional_analysis.json': {\n",
    "            'description': 'Analysis grouped by region/province',\n",
    "            'regions': len(regional_analysis) if 'Region' in enriched_data.columns else 0,\n",
    "            'size_kb': round((json_export_dir / 'regional_analysis.json').stat().st_size / 1024, 2) if (json_export_dir / 'regional_analysis.json').exists() else 0\n",
    "        },\n",
    "        'expenditure_trends.json': {\n",
    "            'description': 'Year-over-year expenditure trends (2023-2024)',\n",
    "            'records': len(trends_data),\n",
    "            'size_kb': round((json_export_dir / 'expenditure_trends.json').stat().st_size / 1024, 2)\n",
    "        }\n",
    "    },\n",
    "    'endpoints': [\n",
    "        {'path': '/api/health', 'method': 'GET', 'description': 'Health check'},\n",
    "        {'path': '/api/clusters', 'method': 'GET', 'description': 'Get all clusters with filters'},\n",
    "        {'path': '/api/clusters/<id>', 'method': 'GET', 'description': 'Get specific cluster details'},\n",
    "        {'path': '/api/statistics', 'method': 'GET', 'description': 'Get summary statistics'},\n",
    "        {'path': '/api/predictions', 'method': 'GET', 'description': 'Get 2025 predictions'},\n",
    "        {'path': '/api/regions', 'method': 'GET', 'description': 'Get regional statistics'},\n",
    "        {'path': '/api/search', 'method': 'GET', 'description': 'Search kabupaten by name'},\n",
    "        {'path': '/api/visualization', 'method': 'GET', 'description': 'Get visualization data'}\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(json_export_dir / 'api_metadata.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(api_metadata, f, indent=2, ensure_ascii=False)\n",
    "print(f\"   ✓ Exported: API metadata and documentation\")\n",
    "\n",
    "# ============================================\n",
    "# SUMMARY\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BATCH JSON EXPORT - COMPLETED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nExport Directory: {json_export_dir.absolute()}\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  1. all_clusters.json         - {len(enriched_data)} records\")\n",
    "print(f\"  2. cluster_details.json      - {len(cluster_details)} clusters\")\n",
    "print(f\"  3. predictions_full.json     - {len(predictions_2025)} predictions\")\n",
    "print(f\"  4. regional_analysis.json    - {len(regional_analysis) if 'Region' in enriched_data.columns else 0} regions\")\n",
    "print(f\"  5. expenditure_trends.json   - {len(trends_data)} trends\")\n",
    "print(f\"  6. api_metadata.json         - API documentation\")\n",
    "\n",
    "# Calculate total size\n",
    "total_size = sum([f.stat().st_size for f in json_export_dir.glob('*.json')])\n",
    "print(f\"\\nTotal size: {total_size / 1024:.2f} KB ({total_size / (1024*1024):.2f} MB)\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n✓ All JSON files ready for API consumption!\")\n",
    "print(\"✓ Files can be served statically or loaded by backend API\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef33b243",
   "metadata": {},
   "source": [
    "## 12. Verifikasi File JSON\n",
    "\n",
    "Membaca dan memverifikasi semua file JSON yang telah dibuat untuk memastikan struktur data benar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfff8bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "JSON FILES VERIFICATION\n",
      "============================================================\n",
      "\n",
      "📄 all_clusters.json\n",
      "────────────────────────────────────────────────────────────\n",
      "   Size: 149.11 KB\n",
      "   Valid JSON: ✓\n",
      "   Metadata: ✓\n",
      "   Records: 514\n",
      "   Top-level keys: ['metadata', 'data']\n",
      "   Sample record keys: ['Kabupaten_Kota', 'Tahun', 'Region', 'Pengeluaran_Buah', 'Pengeluaran_Sayur']...\n",
      "\n",
      "📄 api_metadata.json\n",
      "────────────────────────────────────────────────────────────\n",
      "   Size: 2.01 KB\n",
      "   Valid JSON: ✓\n",
      "   Top-level keys: ['api_version', 'generated_at', 'data_summary', 'files', 'endpoints']\n",
      "\n",
      "📄 cluster_details.json\n",
      "────────────────────────────────────────────────────────────\n",
      "   Size: 5.72 KB\n",
      "   Valid JSON: ✓\n",
      "   Metadata: ✓\n",
      "   Clusters: 3\n",
      "   Top-level keys: ['metadata', 'clusters']\n",
      "   Sample cluster keys: ['cluster_id', 'cluster_label', 'size', 'percentage', 'profile']...\n",
      "\n",
      "📄 expenditure_trends.json\n",
      "────────────────────────────────────────────────────────────\n",
      "   Size: 0.17 KB\n",
      "   Valid JSON: ✓\n",
      "   Metadata: ✓\n",
      "   Top-level keys: ['metadata', 'trends']\n",
      "\n",
      "📄 predictions_full.json\n",
      "────────────────────────────────────────────────────────────\n",
      "   Size: 0.25 KB\n",
      "   Valid JSON: ✓\n",
      "   Metadata: ✓\n",
      "   Predictions: 0\n",
      "   Top-level keys: ['metadata', 'predictions', 'summary_by_cluster']\n",
      "\n",
      "📄 regional_analysis.json\n",
      "────────────────────────────────────────────────────────────\n",
      "   Size: 20.48 KB\n",
      "   Valid JSON: ✓\n",
      "   Metadata: ✓\n",
      "   Regions: 35\n",
      "   Top-level keys: ['metadata', 'regions']\n",
      "   Sample region keys: ['region', 'total_kabupaten', 'percentage', 'cluster_distribution', 'expenditure']...\n",
      "\n",
      "============================================================\n",
      "✓ Verification complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify all JSON files\n",
    "json_files = list(json_export_dir.glob('*.json'))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"JSON FILES VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for json_file in sorted(json_files):\n",
    "    print(f\"\\n📄 {json_file.name}\")\n",
    "    print(\"─\" * 60)\n",
    "    \n",
    "    try:\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Get file size\n",
    "        size_kb = json_file.stat().st_size / 1024\n",
    "        \n",
    "        print(f\"   Size: {size_kb:.2f} KB\")\n",
    "        print(f\"   Valid JSON: ✓\")\n",
    "        \n",
    "        # Show structure based on file type\n",
    "        if 'metadata' in data:\n",
    "            print(f\"   Metadata: ✓\")\n",
    "            if 'total_records' in data['metadata']:\n",
    "                print(f\"   Records: {data['metadata']['total_records']}\")\n",
    "            if 'total_clusters' in data['metadata']:\n",
    "                print(f\"   Clusters: {data['metadata']['total_clusters']}\")\n",
    "            if 'total_predictions' in data['metadata']:\n",
    "                print(f\"   Predictions: {data['metadata']['total_predictions']}\")\n",
    "            if 'total_regions' in data['metadata']:\n",
    "                print(f\"   Regions: {data['metadata']['total_regions']}\")\n",
    "        \n",
    "        # Count top-level keys\n",
    "        print(f\"   Top-level keys: {list(data.keys())}\")\n",
    "        \n",
    "        # Sample first record if available\n",
    "        if 'data' in data and len(data['data']) > 0:\n",
    "            print(f\"   Sample record keys: {list(data['data'][0].keys())[:5]}...\")\n",
    "        elif 'clusters' in data and len(data['clusters']) > 0:\n",
    "            print(f\"   Sample cluster keys: {list(data['clusters'][0].keys())[:5]}...\")\n",
    "        elif 'regions' in data and len(data['regions']) > 0:\n",
    "            print(f\"   Sample region keys: {list(data['regions'][0].keys())[:5]}...\")\n",
    "        elif 'predictions' in data and len(data['predictions']) > 0:\n",
    "            print(f\"   Sample prediction keys: {list(data['predictions'][0].keys())[:5]}...\")\n",
    "        elif 'trends' in data and len(data['trends']) > 0:\n",
    "            print(f\"   Sample trend keys: {list(data['trends'][0].keys())[:5]}...\")\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"   ✗ Invalid JSON: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ Verification complete!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
