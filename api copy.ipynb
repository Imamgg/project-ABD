{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a34d127",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4a6718",
   "metadata": {},
   "source": [
    "## 1. Setup & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a1048c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install flask flask-cors pandas numpy scikit-learn python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "382c6842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, request\n",
    "from flask_cors import CORS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70036e4",
   "metadata": {},
   "source": [
    "## 2. Load Data from Modeling Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "076cd37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA LOADED SUCCESSFULLY\n",
      "============================================================\n",
      "Clustering Results: (514, 6)\n",
      "Cluster Profiles: (3, 11)\n",
      "Cluster Centroids: (3, 3)\n",
      "Integrated Data: (1028, 47)\n",
      "\n",
      "Clustering Results columns:\n",
      "['Kabupaten_Kota', 'Tahun', 'Region', 'Pengeluaran_Buah', 'Pengeluaran_Sayur', 'Cluster']\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kabupaten_Kota</th>\n",
       "      <th>Tahun</th>\n",
       "      <th>Region</th>\n",
       "      <th>Pengeluaran_Buah</th>\n",
       "      <th>Pengeluaran_Sayur</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aceh Barat</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>11160.0</td>\n",
       "      <td>15821.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aceh Barat Daya</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>7231.0</td>\n",
       "      <td>13790.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aceh Besar</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>6689.0</td>\n",
       "      <td>14052.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aceh Jaya</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>8789.0</td>\n",
       "      <td>14197.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aceh Selatan</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>5682.0</td>\n",
       "      <td>14771.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Kabupaten_Kota  Tahun Region  Pengeluaran_Buah  Pengeluaran_Sayur  Cluster\n",
       "0       Aceh Barat   2024   Aceh           11160.0            15821.0        0\n",
       "1  Aceh Barat Daya   2024   Aceh            7231.0            13790.0        1\n",
       "2       Aceh Besar   2024   Aceh            6689.0            14052.0        1\n",
       "3        Aceh Jaya   2024   Aceh            8789.0            14197.0        1\n",
       "4     Aceh Selatan   2024   Aceh            5682.0            14771.0        1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define paths\n",
    "DATA_DIR = Path('data/result')\n",
    "CLEANED_DIR = Path('data/cleaned')\n",
    "\n",
    "# Load clustering results\n",
    "clustering_results = pd.read_csv(DATA_DIR / 'clustering_results.csv')\n",
    "cluster_profiles = pd.read_csv(DATA_DIR / 'cluster_profiles.csv')\n",
    "cluster_centroids = pd.read_csv(DATA_DIR / 'cluster_centroids.csv')\n",
    "\n",
    "# Load cleaned data for additional features\n",
    "data_integrated = pd.read_csv(CLEANED_DIR / 'data_integrated_wide.csv')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA LOADED SUCCESSFULLY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Clustering Results: {clustering_results.shape}\")\n",
    "print(f\"Cluster Profiles: {cluster_profiles.shape}\")\n",
    "print(f\"Cluster Centroids: {cluster_centroids.shape}\")\n",
    "print(f\"Integrated Data: {data_integrated.shape}\")\n",
    "print(\"\\nClustering Results columns:\")\n",
    "print(clustering_results.columns.tolist())\n",
    "print(\"\\nSample data:\")\n",
    "clustering_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68946c3a",
   "metadata": {},
   "source": [
    "## 3. Data Processing & Preparation\n",
    "\n",
    "Prepare data untuk API responses dengan enrichment dan transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d20afae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data preparation complete!\n",
      "\n",
      "Enriched data shape: (514, 8)\n",
      "\n",
      "New columns added:\n",
      "['Cluster_Label', 'Cluster_Category']\n",
      "\n",
      "Sample enriched data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kabupaten_Kota</th>\n",
       "      <th>Tahun</th>\n",
       "      <th>Region</th>\n",
       "      <th>Pengeluaran_Buah</th>\n",
       "      <th>Pengeluaran_Sayur</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Cluster_Label</th>\n",
       "      <th>Cluster_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aceh Barat</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>11160.0</td>\n",
       "      <td>15821.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Low Expenditure</td>\n",
       "      <td>Low Expenditure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aceh Barat Daya</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>7231.0</td>\n",
       "      <td>13790.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Balanced Expenditure</td>\n",
       "      <td>Balanced Expenditure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aceh Besar</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>6689.0</td>\n",
       "      <td>14052.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Balanced Expenditure</td>\n",
       "      <td>Balanced Expenditure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aceh Jaya</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>8789.0</td>\n",
       "      <td>14197.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Balanced Expenditure</td>\n",
       "      <td>Balanced Expenditure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aceh Selatan</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aceh</td>\n",
       "      <td>5682.0</td>\n",
       "      <td>14771.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Balanced Expenditure</td>\n",
       "      <td>Balanced Expenditure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Kabupaten_Kota  Tahun Region  Pengeluaran_Buah  Pengeluaran_Sayur  \\\n",
       "0       Aceh Barat   2024   Aceh           11160.0            15821.0   \n",
       "1  Aceh Barat Daya   2024   Aceh            7231.0            13790.0   \n",
       "2       Aceh Besar   2024   Aceh            6689.0            14052.0   \n",
       "3        Aceh Jaya   2024   Aceh            8789.0            14197.0   \n",
       "4     Aceh Selatan   2024   Aceh            5682.0            14771.0   \n",
       "\n",
       "   Cluster         Cluster_Label      Cluster_Category  \n",
       "0        0       Low Expenditure       Low Expenditure  \n",
       "1        1  Balanced Expenditure  Balanced Expenditure  \n",
       "2        1  Balanced Expenditure  Balanced Expenditure  \n",
       "3        1  Balanced Expenditure  Balanced Expenditure  \n",
       "4        1  Balanced Expenditure  Balanced Expenditure  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_cluster_data():\n",
    "    \"\"\"\n",
    "    Prepare enriched cluster data dengan tambahan informasi:\n",
    "    - Region mapping\n",
    "    - Cluster labels yang lebih deskriptif\n",
    "    - Category classification\n",
    "    \"\"\"\n",
    "\n",
    "    # Add cluster labels berdasarkan profil\n",
    "    cluster_labels = {\n",
    "        0: \"Low Expenditure\",\n",
    "        1: \"Balanced Expenditure\",\n",
    "        2: \"High Expenditure\",\n",
    "    }\n",
    "\n",
    "    # Enrich clustering results\n",
    "    df = clustering_results.copy()\n",
    "    df['Cluster_Label'] = df['Cluster'].map(cluster_labels)\n",
    "\n",
    "    # Add category based on expenditure levels\n",
    "    df['Cluster_Category'] = df['Cluster_Label']\n",
    "\n",
    "    return df\n",
    "\n",
    "# Process data\n",
    "enriched_data = prepare_cluster_data()\n",
    "\n",
    "print(\"✓ Data preparation complete!\")\n",
    "print(f\"\\nEnriched data shape: {enriched_data.shape}\")\n",
    "print(\"\\nNew columns added:\")\n",
    "print([col for col in enriched_data.columns if col not in clustering_results.columns])\n",
    "print(\"\\nSample enriched data:\")\n",
    "enriched_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22f8273",
   "metadata": {},
   "source": [
    "## 4. Generate Predictions for 2025\n",
    "\n",
    "Menggunakan Linear Regression untuk prediksi tren pengeluaran tahun 2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c30621dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Predictions generated for 2025!\n",
      "\n",
      "Total predictions: 0\n",
      "\n",
      "Sample predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_predictions_2025():\n",
    "    \"\"\"\n",
    "    Generate predictions untuk pengeluaran 2025 berdasarkan tren 2023-2024\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    # Group by Kabupaten_Kota untuk time series\n",
    "    for kabupaten in enriched_data['Kabupaten_Kota'].unique():\n",
    "        kab_data = enriched_data[enriched_data['Kabupaten_Kota'] == kabupaten].sort_values('Tahun')\n",
    "        \n",
    "        if len(kab_data) >= 2:  # Need at least 2 years for prediction\n",
    "            years = kab_data['Tahun'].values.reshape(-1, 1)\n",
    "            \n",
    "            # Predict Buah\n",
    "            if 'Total_Buah' in kab_data.columns:\n",
    "                buah_values = kab_data['Total_Buah'].values\n",
    "                model_buah = LinearRegression()\n",
    "                model_buah.fit(years, buah_values)\n",
    "                pred_buah_2025 = model_buah.predict([[2025]])[0]\n",
    "            else:\n",
    "                pred_buah_2025 = kab_data['Pengeluaran_Buah'].iloc[-1] * 1.05  # 5% growth assumption\n",
    "            \n",
    "            # Predict Sayur\n",
    "            if 'Total_Sayur' in kab_data.columns:\n",
    "                sayur_values = kab_data['Total_Sayur'].values\n",
    "                model_sayur = LinearRegression()\n",
    "                model_sayur.fit(years, sayur_values)\n",
    "                pred_sayur_2025 = model_sayur.predict([[2025]])[0]\n",
    "            else:\n",
    "                pred_sayur_2025 = kab_data['Pengeluaran_Sayur'].iloc[-1] * 1.05\n",
    "            \n",
    "            # Get latest cluster info\n",
    "            latest = kab_data.iloc[-1]\n",
    "            \n",
    "            predictions.append({\n",
    "                'Kabupaten_Kota': kabupaten,\n",
    "                'Region': latest.get('Region', 'Unknown'),\n",
    "                'Cluster': int(latest['Cluster']),\n",
    "                'Cluster_Label': latest['Cluster_Label'],\n",
    "                'Predicted_Buah_2025': float(pred_buah_2025),\n",
    "                'Predicted_Sayur_2025': float(pred_sayur_2025),\n",
    "                'Predicted_Total_2025': float(pred_buah_2025 + pred_sayur_2025),\n",
    "                'Current_Buah_2024': float(latest.get('Total_Buah', latest.get('Pengeluaran_Buah', 0))),\n",
    "                'Current_Sayur_2024': float(latest.get('Total_Sayur', latest.get('Pengeluaran_Sayur', 0))),\n",
    "                'Growth_Rate_Buah': float((pred_buah_2025 / latest.get('Total_Buah', latest.get('Pengeluaran_Buah', 1)) - 1) * 100),\n",
    "                'Growth_Rate_Sayur': float((pred_sayur_2025 / latest.get('Total_Sayur', latest.get('Pengeluaran_Sayur', 1)) - 1) * 100)\n",
    "            })\n",
    "    \n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "    return predictions_df\n",
    "\n",
    "# Generate predictions\n",
    "predictions_2025 = generate_predictions_2025()\n",
    "\n",
    "print(\"✓ Predictions generated for 2025!\")\n",
    "print(f\"\\nTotal predictions: {len(predictions_2025)}\")\n",
    "print(\"\\nSample predictions:\")\n",
    "predictions_2025.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08dfa92",
   "metadata": {},
   "source": [
    "## 5. Create Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c97f9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Summary statistics generated!\n",
      "\n",
      "Overview:\n",
      "{\n",
      "  \"total_kabupaten\": 514,\n",
      "  \"total_clusters\": 3,\n",
      "  \"years_covered\": [\n",
      "    2024\n",
      "  ],\n",
      "  \"total_data_points\": 514\n",
      "}\n",
      "\n",
      "Cluster Distribution:\n",
      "{\n",
      "  \"0\": 209,\n",
      "  \"1\": 298,\n",
      "  \"2\": 7\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def generate_summary_statistics():\n",
    "    \"\"\"\n",
    "    Generate comprehensive summary statistics untuk dashboard\n",
    "    \"\"\"\n",
    "    \n",
    "    stats = {\n",
    "        'overview': {\n",
    "            'total_kabupaten': int(enriched_data['Kabupaten_Kota'].nunique()),\n",
    "            'total_clusters': int(enriched_data['Cluster'].nunique()),\n",
    "            'years_covered': sorted(enriched_data['Tahun'].unique().tolist()),\n",
    "            'total_data_points': int(len(enriched_data))\n",
    "        },\n",
    "        'cluster_distribution': enriched_data.groupby('Cluster')['Kabupaten_Kota'].count().to_dict(),\n",
    "        'cluster_labels': enriched_data.groupby('Cluster')['Cluster_Label'].first().to_dict(),\n",
    "        'regional_distribution': enriched_data['Region'].value_counts().to_dict() if 'Region' in enriched_data.columns else {},\n",
    "        'expenditure_summary': {\n",
    "            'avg_buah': float(enriched_data.get('Total_Buah', enriched_data.get('Pengeluaran_Buah', pd.Series([0]))).mean()),\n",
    "            'avg_sayur': float(enriched_data.get('Total_Sayur', enriched_data.get('Pengeluaran_Sayur', pd.Series([0]))).mean()),\n",
    "            'max_buah': float(enriched_data.get('Total_Buah', enriched_data.get('Pengeluaran_Buah', pd.Series([0]))).max()),\n",
    "            'max_sayur': float(enriched_data.get('Total_Sayur', enriched_data.get('Pengeluaran_Sayur', pd.Series([0]))).max()),\n",
    "            'min_buah': float(enriched_data.get('Total_Buah', enriched_data.get('Pengeluaran_Buah', pd.Series([0]))).min()),\n",
    "            'min_sayur': float(enriched_data.get('Total_Sayur', enriched_data.get('Pengeluaran_Sayur', pd.Series([0]))).min())\n",
    "        },\n",
    "        'cluster_profiles': cluster_profiles.to_dict('records'),\n",
    "        'centroids': cluster_centroids.to_dict('records')\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Generate statistics\n",
    "summary_stats = generate_summary_statistics()\n",
    "\n",
    "print(\"✓ Summary statistics generated!\")\n",
    "print(\"\\nOverview:\")\n",
    "print(json.dumps(summary_stats['overview'], indent=2))\n",
    "print(\"\\nCluster Distribution:\")\n",
    "print(json.dumps(summary_stats['cluster_distribution'], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85145277",
   "metadata": {},
   "source": [
    "## 6. Export Data for Frontend\n",
    "\n",
    "Export processed data ke format yang mudah dikonsumsi oleh frontend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc2a9819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Exported: frontend\\public\\data\\modeling\\predictions_2025.csv\n",
      "✓ Exported: frontend\\public\\data\\modeling\\summary_statistics.json\n",
      "✓ Exported: frontend\\public\\data\\modeling\\visualization_data.json\n",
      "\n",
      "============================================================\n",
      "DATA EXPORT COMPLETE\n",
      "============================================================\n",
      "Files exported to: d:\\Perkuliahan\\2025-2026\\Analisa Big Data\\ProjectABD\\frontend\\public\\data\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "frontend_data_dir = Path('frontend/public/data')\n",
    "frontend_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Export predictions\n",
    "predictions_2025.to_csv(frontend_data_dir / 'modeling/predictions_2025.csv', index=False)\n",
    "print(f\"✓ Exported: {frontend_data_dir / 'modeling/predictions_2025.csv'}\")\n",
    "\n",
    "# Export summary statistics as JSON\n",
    "with open(frontend_data_dir / 'modeling/summary_statistics.json', 'w') as f:\n",
    "    json.dump(summary_stats, f, indent=2)\n",
    "print(f\"✓ Exported: {frontend_data_dir / 'modeling/summary_statistics.json'}\")\n",
    "\n",
    "# Create visualization data for charts\n",
    "viz_data = {\n",
    "    'cluster_sizes': enriched_data.groupby(['Cluster', 'Cluster_Label']).size().reset_index(name='count').to_dict('records'),\n",
    "    'expenditure_by_cluster': clustering_results.groupby('Cluster').agg({\n",
    "        'Pengeluaran_Buah': 'mean',\n",
    "        'Pengeluaran_Sayur': 'mean'\n",
    "    }).reset_index().to_dict('records'),\n",
    "}\n",
    "\n",
    "with open(frontend_data_dir / 'modeling/visualization_data.json', 'w') as f:\n",
    "    json.dump(viz_data, f, indent=2)\n",
    "print(f\"✓ Exported: {frontend_data_dir / 'modeling/visualization_data.json'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA EXPORT COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Files exported to: {frontend_data_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd8d993",
   "metadata": {},
   "source": [
    "## 7. Flask API Application\n",
    "\n",
    "Create REST API endpoints untuk frontend consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518ef978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Flask API initialized successfully!\n",
      "\n",
      "Available endpoints:\n",
      "  GET  /api/health\n",
      "  GET  /api/clusters\n",
      "  GET  /api/clusters/<id>\n",
      "  GET  /api/statistics\n",
      "  GET  /api/predictions\n",
      "  GET  /api/regions\n",
      "  GET  /api/search\n",
      "  GET  /api/visualization\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable CORS for all routes\n",
    "\n",
    "# ============================================\n",
    "# API ENDPOINTS\n",
    "# ============================================\n",
    "\n",
    "@app.route('/api/health', methods=['GET'])\n",
    "def health_check():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return jsonify({\n",
    "        'status': 'healthy',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'version': '1.0.0'\n",
    "    })\n",
    "\n",
    "@app.route('/api/clusters', methods=['GET'])\n",
    "def get_all_clusters():\n",
    "    \"\"\"\n",
    "    Get all clustering data\n",
    "    Query params:\n",
    "    - year: Filter by year (2023, 2024)\n",
    "    - cluster: Filter by cluster ID\n",
    "    - region: Filter by region\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = enriched_data.copy()\n",
    "        \n",
    "        # Apply filters\n",
    "        if 'year' in request.args:\n",
    "            year = int(request.args.get('year'))\n",
    "            df = df[df['Tahun'] == year]\n",
    "        \n",
    "        if 'cluster' in request.args:\n",
    "            cluster = int(request.args.get('cluster'))\n",
    "            df = df[df['Cluster'] == cluster]\n",
    "        \n",
    "        if 'region' in request.args:\n",
    "            region = request.args.get('region')\n",
    "            if 'Region' in df.columns:\n",
    "                df = df[df['Region'] == region]\n",
    "        \n",
    "        # Convert to JSON-friendly format\n",
    "        result = df.to_dict('records')\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'count': len(result),\n",
    "            'data': result\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/clusters/<int:cluster_id>', methods=['GET'])\n",
    "def get_cluster_by_id(cluster_id):\n",
    "    \"\"\"\n",
    "    Get specific cluster data and profile\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get cluster data\n",
    "        cluster_data = enriched_data[enriched_data['Cluster'] == cluster_id]\n",
    "        \n",
    "        # Get cluster profile\n",
    "        profile = cluster_profiles[cluster_profiles['Cluster'] == cluster_id].to_dict('records')\n",
    "        \n",
    "        # Get centroid\n",
    "        centroid = cluster_centroids[cluster_centroids['Cluster'] == cluster_id].to_dict('records')\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'cluster_id': cluster_id,\n",
    "            'profile': profile[0] if profile else {},\n",
    "            'centroid': centroid[0] if centroid else {},\n",
    "            'data': cluster_data.to_dict('records'),\n",
    "            'count': len(cluster_data)\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/statistics', methods=['GET'])\n",
    "def get_statistics():\n",
    "    \"\"\"\n",
    "    Get summary statistics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'data': summary_stats\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/predictions', methods=['GET'])\n",
    "def get_predictions():\n",
    "    \"\"\"\n",
    "    Get predictions for 2025\n",
    "    Query params:\n",
    "    - cluster: Filter by cluster ID\n",
    "    - kabupaten: Search by kabupaten name\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = predictions_2025.copy()\n",
    "        \n",
    "        if 'cluster' in request.args:\n",
    "            cluster = int(request.args.get('cluster'))\n",
    "            df = df[df['Cluster'] == cluster]\n",
    "        \n",
    "        if 'kabupaten' in request.args:\n",
    "            kabupaten = request.args.get('kabupaten').lower()\n",
    "            df = df[df['Kabupaten_Kota'].str.lower().str.contains(kabupaten)]\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'count': len(df),\n",
    "            'data': df.to_dict('records')\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/regions', methods=['GET'])\n",
    "def get_regions():\n",
    "    \"\"\"\n",
    "    Get unique regions and their statistics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if 'Region' not in enriched_data.columns:\n",
    "            return jsonify({\n",
    "                'success': False,\n",
    "                'error': 'Region data not available'\n",
    "            }), 404\n",
    "        \n",
    "        regions = enriched_data.groupby('Region').agg({\n",
    "            'Kabupaten_Kota': 'count',\n",
    "            'Total_Buah': 'mean' if 'Total_Buah' in enriched_data.columns else lambda x: 0,\n",
    "            'Total_Sayur': 'mean' if 'Total_Sayur' in enriched_data.columns else lambda x: 0\n",
    "        }).reset_index()\n",
    "        \n",
    "        regions.columns = ['Region', 'Count', 'Avg_Buah', 'Avg_Sayur']\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'data': regions.to_dict('records')\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/search', methods=['GET'])\n",
    "def search_kabupaten():\n",
    "    \"\"\"\n",
    "    Search kabupaten/kota by name\n",
    "    Query params:\n",
    "    - q: Search query\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query = request.args.get('q', '').lower()\n",
    "        \n",
    "        if not query:\n",
    "            return jsonify({\n",
    "                'success': False,\n",
    "                'error': 'Query parameter q is required'\n",
    "            }), 400\n",
    "        \n",
    "        results = enriched_data[\n",
    "            enriched_data['Kabupaten_Kota'].str.lower().str.contains(query)\n",
    "        ]\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'query': query,\n",
    "            'count': len(results),\n",
    "            'data': results.to_dict('records')\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/visualization', methods=['GET'])\n",
    "def get_visualization_data():\n",
    "    \"\"\"\n",
    "    Get pre-processed data for visualizations\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'data': viz_data\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "print(\"✓ Flask API initialized successfully!\")\n",
    "print(\"\\nAvailable endpoints:\")\n",
    "print(\"  GET  /api/health\")\n",
    "print(\"  GET  /api/clusters\")\n",
    "print(\"  GET  /api/clusters/<id>\")\n",
    "print(\"  GET  /api/statistics\")\n",
    "print(\"  GET  /api/predictions\")\n",
    "print(\"  GET  /api/regions\")\n",
    "print(\"  GET  /api/search\")\n",
    "print(\"  GET  /api/visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753cbd8d",
   "metadata": {},
   "source": [
    "## 8. Save Flask App to Python File\n",
    "\n",
    "**Note**: Flask server tidak bisa dijalankan langsung di Jupyter notebook.\n",
    "Kita akan save Flask app ke file `api.py` yang bisa dijalankan di terminal.\n",
    "\n",
    "**Cara menjalankan**:\n",
    "\n",
    "**Option 1 - Jalankan di Jupyter Notebook/VS Code**:\n",
    "- Jalankan semua cell di notebook ini (cell 1-13)\n",
    "- File `api.py` akan otomatis dibuat\n",
    "- Lalu jalankan `api.py` di terminal\n",
    "\n",
    "**Option 2 - Langsung di terminal**:\n",
    "```powershell\n",
    "# Di terminal\n",
    "python api.py\n",
    "```\n",
    "\n",
    "**Option 3 - Production dengan Gunicorn**:\n",
    "```powershell\n",
    "pip install gunicorn\n",
    "gunicorn -w 4 -b 0.0.0.0:5000 api:app\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9061c539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Flask API saved to api.py\n",
      "\n",
      "============================================================\n",
      "TO RUN THE API SERVER:\n",
      "============================================================\n",
      "\n",
      "Option 1 - Development mode:\n",
      "  python api.py\n",
      "\n",
      "Option 2 - Production mode (install gunicorn first):\n",
      "  pip install gunicorn\n",
      "  gunicorn -w 4 -b 0.0.0.0:5000 api:app\n",
      "\n",
      "Option 3 - Run in background (Windows PowerShell):\n",
      "  Start-Process python -ArgumentList 'api.py' -WindowStyle Hidden\n",
      "\n",
      "============================================================\n",
      "\n",
      "API will be available at: http://localhost:5000/api\n",
      "Test with: http://localhost:5000/api/health\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Save Flask app to api.py file\n",
    "flask_code = '''from flask import Flask, jsonify, request\n",
    "from flask_cors import CORS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "DATA_DIR = Path('data/modeling')\n",
    "CLEANED_DIR = Path('data/cleaned')\n",
    "\n",
    "clustering_results = pd.read_csv(DATA_DIR / 'clustering_results.csv')\n",
    "cluster_profiles = pd.read_csv(DATA_DIR / 'cluster_profiles.csv')\n",
    "cluster_centroids = pd.read_csv(DATA_DIR / 'cluster_centroids.csv')\n",
    "data_integrated = pd.read_csv(CLEANED_DIR / 'data_integrated_wide.csv')\n",
    "\n",
    "# Prepare enriched data\n",
    "enriched_data = clustering_results.copy()\n",
    "\n",
    "# Load predictions\n",
    "predictions_2025 = pd.read_csv(Path('frontend/public/data/modeling/predictions_2025.csv'))\n",
    "\n",
    "# Load summary stats\n",
    "with open(Path('frontend/public/data/modeling/summary_statistics.json'), 'r') as f:\n",
    "    summary_stats = json.load(f)\n",
    "\n",
    "# Load viz data\n",
    "with open(Path('frontend/public/data/modeling/visualization_data.json'), 'r') as f:\n",
    "    viz_data = json.load(f)\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "@app.route('/api/health', methods=['GET'])\n",
    "def health_check():\n",
    "    return jsonify({\n",
    "        'status': 'healthy',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'version': '1.0.0'\n",
    "    })\n",
    "\n",
    "@app.route('/api/clusters', methods=['GET'])\n",
    "def get_all_clusters():\n",
    "    try:\n",
    "        df = enriched_data.copy()\n",
    "        \n",
    "        if 'year' in request.args:\n",
    "            year = int(request.args.get('year'))\n",
    "            df = df[df['Tahun'] == year]\n",
    "        \n",
    "        if 'cluster' in request.args:\n",
    "            cluster = int(request.args.get('cluster'))\n",
    "            df = df[df['Cluster'] == cluster]\n",
    "        \n",
    "        if 'region' in request.args:\n",
    "            region = request.args.get('region')\n",
    "            if 'Region' in df.columns:\n",
    "                df = df[df['Region'] == region]\n",
    "        \n",
    "        result = df.to_dict('records')\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'count': len(result),\n",
    "            'data': result\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/clusters/<int:cluster_id>', methods=['GET'])\n",
    "def get_cluster_by_id(cluster_id):\n",
    "    try:\n",
    "        cluster_data = enriched_data[enriched_data['Cluster'] == cluster_id]\n",
    "        profile = cluster_profiles[cluster_profiles['Cluster'] == cluster_id].to_dict('records')\n",
    "        centroid = cluster_centroids[cluster_centroids['Cluster'] == cluster_id].to_dict('records')\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'cluster_id': cluster_id,\n",
    "            'profile': profile[0] if profile else {},\n",
    "            'centroid': centroid[0] if centroid else {},\n",
    "            'data': cluster_data.to_dict('records'),\n",
    "            'count': len(cluster_data)\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/statistics', methods=['GET'])\n",
    "def get_statistics():\n",
    "    try:\n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'data': summary_stats\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/predictions', methods=['GET'])\n",
    "def get_predictions():\n",
    "    try:\n",
    "        df = predictions_2025.copy()\n",
    "        \n",
    "        if 'cluster' in request.args:\n",
    "            cluster = int(request.args.get('cluster'))\n",
    "            df = df[df['Cluster'] == cluster]\n",
    "        \n",
    "        if 'kabupaten' in request.args:\n",
    "            kabupaten = request.args.get('kabupaten').lower()\n",
    "            df = df[df['Kabupaten_Kota'].str.lower().str.contains(kabupaten)]\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'count': len(df),\n",
    "            'data': df.to_dict('records')\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/regions', methods=['GET'])\n",
    "def get_regions():\n",
    "    try:\n",
    "        if 'Region' not in enriched_data.columns:\n",
    "            return jsonify({\n",
    "                'success': False,\n",
    "                'error': 'Region data not available'\n",
    "            }), 404\n",
    "        \n",
    "        regions = enriched_data.groupby('Region').agg({\n",
    "            'Kabupaten_Kota': 'count',\n",
    "            'Total_Buah': 'mean' if 'Total_Buah' in enriched_data.columns else lambda x: 0,\n",
    "            'Total_Sayur': 'mean' if 'Total_Sayur' in enriched_data.columns else lambda x: 0\n",
    "        }).reset_index()\n",
    "        \n",
    "        regions.columns = ['Region', 'Count', 'Avg_Buah', 'Avg_Sayur']\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'data': regions.to_dict('records')\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/search', methods=['GET'])\n",
    "def search_kabupaten():\n",
    "    try:\n",
    "        query = request.args.get('q', '').lower()\n",
    "        \n",
    "        if not query:\n",
    "            return jsonify({\n",
    "                'success': False,\n",
    "                'error': 'Query parameter q is required'\n",
    "            }), 400\n",
    "        \n",
    "        results = enriched_data[\n",
    "            enriched_data['Kabupaten_Kota'].str.lower().str.contains(query)\n",
    "        ]\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'query': query,\n",
    "            'count': len(results),\n",
    "            'data': results.to_dict('records')\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/visualization', methods=['GET'])\n",
    "def get_visualization_data():\n",
    "    try:\n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'data': viz_data\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"=\"*60)\n",
    "    print(\"STARTING FLASK API SERVER\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\\\nServer Configuration:\")\n",
    "    print(\"  Host: 0.0.0.0\")\n",
    "    print(\"  Port: 5000\")\n",
    "    print(\"  Debug: True\")\n",
    "    print(\"  CORS: Enabled\")\n",
    "    print(\"\\\\nAPI Base URL: http://localhost:5000/api\")\n",
    "    print(\"\\\\nPress CTRL+C to stop the server\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    app.run(host='0.0.0.0', port=5000, debug=True)\n",
    "'''\n",
    "\n",
    "# Write to file\n",
    "with open('api.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(flask_code)\n",
    "\n",
    "print(\"✓ Flask API saved to api.py\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TO RUN THE API SERVER:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nOption 1 - Development mode:\")\n",
    "print(\"  python api.py\")\n",
    "print(\"\\nOption 2 - Production mode (install gunicorn first):\")\n",
    "print(\"  pip install gunicorn\")\n",
    "print(\"  gunicorn -w 4 -b 0.0.0.0:5000 api:app\")\n",
    "print(\"\\nOption 3 - Run in background (Windows PowerShell):\")\n",
    "print(\"  Start-Process python -ArgumentList 'api.py' -WindowStyle Hidden\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nAPI will be available at: http://localhost:5000/api\")\n",
    "print(\"Test with: http://localhost:5000/api/health\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f2a464",
   "metadata": {},
   "source": [
    "## 9. API Testing & Examples\n",
    "\n",
    "Test API endpoints menggunakan requests library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a83573a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "API ENDPOINT TESTING\n",
      "============================================================\n",
      "\n",
      "1. Testing /api/health...\n",
      "   Error: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /api/health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001993A7543D0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "\n",
      "2. Testing /api/statistics...\n",
      "   Error: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /api/health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001993A7543D0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "\n",
      "2. Testing /api/statistics...\n",
      "   Error: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /api/statistics (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001993AB33790>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "\n",
      "3. Testing /api/clusters...\n",
      "   Error: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /api/statistics (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001993AB33790>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "\n",
      "3. Testing /api/clusters...\n",
      "   Error: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /api/clusters?year=2024 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001993AB33610>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "\n",
      "4. Testing /api/clusters/0...\n",
      "   Error: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /api/clusters?year=2024 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001993AB33610>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "\n",
      "4. Testing /api/clusters/0...\n",
      "   Error: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /api/clusters/0 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001993AAF9D50>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "\n",
      "5. Testing /api/predictions...\n",
      "   Error: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /api/clusters/0 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001993AAF9D50>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "\n",
      "5. Testing /api/predictions...\n",
      "   Error: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /api/predictions?cluster=0 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001993AB39ED0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "\n",
      "6. Testing /api/search?q=jakarta...\n",
      "   Error: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /api/predictions?cluster=0 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001993AB39ED0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "\n",
      "6. Testing /api/search?q=jakarta...\n",
      "   Error: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /api/search?q=jakarta (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001993AB3BF90>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "\n",
      "============================================================\n",
      "✓ API Testing Complete!\n",
      "============================================================\n",
      "   Error: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /api/search?q=jakarta (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001993AB3BF90>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "\n",
      "============================================================\n",
      "✓ API Testing Complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "BASE_URL = 'http://localhost:5000/api'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"API ENDPOINT TESTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test 1: Health Check\n",
    "print(\"\\n1. Testing /api/health...\")\n",
    "try:\n",
    "    response = requests.get(f'{BASE_URL}/health')\n",
    "    print(f\"   Status: {response.status_code}\")\n",
    "    print(f\"   Response: {response.json()}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "# Test 2: Get Statistics\n",
    "print(\"\\n2. Testing /api/statistics...\")\n",
    "try:\n",
    "    response = requests.get(f'{BASE_URL}/statistics')\n",
    "    print(f\"   Status: {response.status_code}\")\n",
    "    data = response.json()\n",
    "    if data['success']:\n",
    "        print(f\"   Total Kabupaten: {data['data']['overview']['total_kabupaten']}\")\n",
    "        print(f\"   Total Clusters: {data['data']['overview']['total_clusters']}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "# Test 3: Get All Clusters\n",
    "print(\"\\n3. Testing /api/clusters...\")\n",
    "try:\n",
    "    response = requests.get(f'{BASE_URL}/clusters?year=2024')\n",
    "    print(f\"   Status: {response.status_code}\")\n",
    "    data = response.json()\n",
    "    if data['success']:\n",
    "        print(f\"   Data count: {data['count']}\")\n",
    "        print(f\"   Sample: {data['data'][0] if data['data'] else 'No data'}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "# Test 4: Get Specific Cluster\n",
    "print(\"\\n4. Testing /api/clusters/0...\")\n",
    "try:\n",
    "    response = requests.get(f'{BASE_URL}/clusters/0')\n",
    "    print(f\"   Status: {response.status_code}\")\n",
    "    data = response.json()\n",
    "    if data['success']:\n",
    "        print(f\"   Cluster ID: {data['cluster_id']}\")\n",
    "        print(f\"   Data count: {data['count']}\")\n",
    "        print(f\"   Profile: {data['profile']}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "# Test 5: Get Predictions\n",
    "print(\"\\n5. Testing /api/predictions...\")\n",
    "try:\n",
    "    response = requests.get(f'{BASE_URL}/predictions?cluster=0')\n",
    "    print(f\"   Status: {response.status_code}\")\n",
    "    data = response.json()\n",
    "    if data['success']:\n",
    "        print(f\"   Predictions count: {data['count']}\")\n",
    "        if data['data']:\n",
    "            sample = data['data'][0]\n",
    "            print(f\"   Sample prediction for {sample['Kabupaten_Kota']}:\")\n",
    "            print(f\"     Predicted Buah 2025: Rp {sample['Predicted_Buah_2025']:,.0f}\")\n",
    "            print(f\"     Growth Rate: {sample['Growth_Rate_Buah']:.2f}%\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "# Test 6: Search\n",
    "print(\"\\n6. Testing /api/search?q=jakarta...\")\n",
    "try:\n",
    "    response = requests.get(f'{BASE_URL}/search?q=jakarta')\n",
    "    print(f\"   Status: {response.status_code}\")\n",
    "    data = response.json()\n",
    "    if data['success']:\n",
    "        print(f\"   Results found: {data['count']}\")\n",
    "        if data['data']:\n",
    "            print(f\"   First result: {data['data'][0]['Kabupaten_Kota']}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ API Testing Complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d16670",
   "metadata": {},
   "source": [
    "## 10. Integration Guide for Frontend\n",
    "\n",
    "### React/TypeScript Integration Example\n",
    "\n",
    "```typescript\n",
    "// services/apiService.ts\n",
    "const API_BASE_URL = 'http://localhost:5000/api';\n",
    "\n",
    "export const apiService = {\n",
    "  // Get all clusters\n",
    "  getClusters: async (filters?: { year?: number; cluster?: number }) => {\n",
    "    const params = new URLSearchParams(filters as any);\n",
    "    const response = await fetch(`${API_BASE_URL}/clusters?${params}`);\n",
    "    return response.json();\n",
    "  },\n",
    "\n",
    "  // Get specific cluster\n",
    "  getClusterById: async (id: number) => {\n",
    "    const response = await fetch(`${API_BASE_URL}/clusters/${id}`);\n",
    "    return response.json();\n",
    "  },\n",
    "\n",
    "  // Get statistics\n",
    "  getStatistics: async () => {\n",
    "    const response = await fetch(`${API_BASE_URL}/statistics`);\n",
    "    return response.json();\n",
    "  },\n",
    "\n",
    "  // Get predictions\n",
    "  getPredictions: async (cluster?: number) => {\n",
    "    const params = cluster ? `?cluster=${cluster}` : '';\n",
    "    const response = await fetch(`${API_BASE_URL}/predictions${params}`);\n",
    "    return response.json();\n",
    "  },\n",
    "\n",
    "  // Search kabupaten\n",
    "  searchKabupaten: async (query: string) => {\n",
    "    const response = await fetch(`${API_BASE_URL}/search?q=${encodeURIComponent(query)}`);\n",
    "    return response.json();\n",
    "  }\n",
    "};\n",
    "```\n",
    "\n",
    "### Usage in React Components\n",
    "\n",
    "```typescript\n",
    "// components/ClusterDashboard.tsx\n",
    "import { useEffect, useState } from 'react';\n",
    "import { apiService } from '../services/apiService';\n",
    "\n",
    "function ClusterDashboard() {\n",
    "  const [statistics, setStatistics] = useState(null);\n",
    "  const [loading, setLoading] = useState(true);\n",
    "\n",
    "  useEffect(() => {\n",
    "    const fetchData = async () => {\n",
    "      try {\n",
    "        const stats = await apiService.getStatistics();\n",
    "        if (stats.success) {\n",
    "          setStatistics(stats.data);\n",
    "        }\n",
    "      } catch (error) {\n",
    "        console.error('Error fetching statistics:', error);\n",
    "      } finally {\n",
    "        setLoading(false);\n",
    "      }\n",
    "    };\n",
    "\n",
    "    fetchData();\n",
    "  }, []);\n",
    "\n",
    "  if (loading) return <div>Loading...</div>;\n",
    "\n",
    "  return (\n",
    "    <div>\n",
    "      <h1>Cluster Analysis Dashboard</h1>\n",
    "      <p>Total Kabupaten: {statistics?.overview.total_kabupaten}</p>\n",
    "      <p>Total Clusters: {statistics?.overview.total_clusters}</p>\n",
    "    </div>\n",
    "  );\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba05235",
   "metadata": {},
   "source": [
    "## 11. Deployment Notes\n",
    "\n",
    "### Production Deployment\n",
    "\n",
    "#### Option 1: Using Gunicorn (Recommended)\n",
    "```bash\n",
    "# Install gunicorn\n",
    "pip install gunicorn\n",
    "\n",
    "# Run with gunicorn\n",
    "gunicorn -w 4 -b 0.0.0.0:5000 api:app\n",
    "```\n",
    "\n",
    "#### Option 2: Using Docker\n",
    "```dockerfile\n",
    "FROM python:3.9-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "\n",
    "EXPOSE 5000\n",
    "\n",
    "CMD [\"gunicorn\", \"-w\", \"4\", \"-b\", \"0.0.0.0:5000\", \"api:app\"]\n",
    "```\n",
    "\n",
    "#### Option 3: Deploy to Cloud\n",
    "- **Heroku**: `git push heroku main`\n",
    "- **Railway**: Connect GitHub repo\n",
    "- **Google Cloud Run**: Deploy containerized app\n",
    "- **AWS EC2**: Traditional server deployment\n",
    "\n",
    "### Environment Variables\n",
    "Create `.env` file:\n",
    "```\n",
    "FLASK_ENV=production\n",
    "SECRET_KEY=your-secret-key\n",
    "API_KEY=your-gemini-api-key\n",
    "```\n",
    "\n",
    "### Security Considerations\n",
    "1. Use HTTPS in production\n",
    "2. Implement rate limiting\n",
    "3. Add authentication for sensitive endpoints\n",
    "4. Validate and sanitize all inputs\n",
    "5. Use environment variables for secrets\n",
    "\n",
    "### Performance Optimization\n",
    "1. Enable caching (Redis/Memcached)\n",
    "2. Use database instead of CSV for large datasets\n",
    "3. Implement pagination for large responses\n",
    "4. Add request compression (gzip)\n",
    "5. Use CDN for static files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c37ddc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3420d923",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "\n",
    "**Data Sources**:\n",
    "- Clustering results\n",
    "- Cluster profiles\n",
    "- Cluster centroids\n",
    "- Integrated data (2023-2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f82e7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA LOADED SUCCESSFULLY\n",
      "============================================================\n",
      "Clustering results: (1028, 9)\n",
      "Cluster profiles: (4, 20)\n",
      "Cluster centroids: (4, 6)\n",
      "Integrated data: (1028, 47)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "modeling_dir = Path('data/modeling')\n",
    "cleaned_dir = Path('data/cleaned')\n",
    "output_dir = Path('frontend/public/data/modeling')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load modeling results\n",
    "df_clustering = pd.read_csv(modeling_dir / 'clustering_results.csv')\n",
    "df_profiles = pd.read_csv(modeling_dir / 'cluster_profiles.csv')\n",
    "df_centroids = pd.read_csv(modeling_dir / 'cluster_centroids.csv')\n",
    "\n",
    "# Load integrated data\n",
    "df_integrated = pd.read_csv(cleaned_dir / 'data_integrated_wide.csv')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA LOADED SUCCESSFULLY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Clustering results: {df_clustering.shape}\")\n",
    "print(f\"Cluster profiles: {df_profiles.shape}\")\n",
    "print(f\"Cluster centroids: {df_centroids.shape}\")\n",
    "print(f\"Integrated data: {df_integrated.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb28014",
   "metadata": {},
   "source": [
    "## 3. Generate Summary Statistics\n",
    "\n",
    "**Tujuan**: Membuat ringkasan statistik untuk dashboard cards.\n",
    "\n",
    "**Metrics**:\n",
    "- Total kabupaten/kota\n",
    "- Number of clusters\n",
    "- Average expenditure per category\n",
    "- Total expenditure across Indonesia\n",
    "- Year-over-year growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ba1f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Summary statistics generated\n",
      "  Total Kabupaten: 514\n",
      "  Total Clusters: 4\n",
      "  Average Expenditure: Rp 45,561/minggu\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Calculate summary statistics\n",
    "summary_stats = {\n",
    "    \"metadata\": {\n",
    "        \"generated_at\": datetime.now().isoformat(),\n",
    "        \"total_kabupaten\": int(df_clustering['Kabupaten_Kota'].nunique()),\n",
    "        \"total_clusters\": int(df_profiles['Cluster'].nunique()),\n",
    "        \"data_year\": int(df_clustering['Tahun'].iloc[0])\n",
    "    },\n",
    "    \"expenditure\": {\n",
    "        \"buah\": {\n",
    "            \"mean\": float(df_clustering['Total_Buah'].mean()),\n",
    "            \"median\": float(df_clustering['Total_Buah'].median()),\n",
    "            \"min\": float(df_clustering['Total_Buah'].min()),\n",
    "            \"max\": float(df_clustering['Total_Buah'].max()),\n",
    "            \"std\": float(df_clustering['Total_Buah'].std())\n",
    "        },\n",
    "        \"sayur\": {\n",
    "            \"mean\": float(df_clustering['Total_Sayur'].mean()),\n",
    "            \"median\": float(df_clustering['Total_Sayur'].median()),\n",
    "            \"min\": float(df_clustering['Total_Sayur'].min()),\n",
    "            \"max\": float(df_clustering['Total_Sayur'].max()),\n",
    "            \"std\": float(df_clustering['Total_Sayur'].std())\n",
    "        },\n",
    "        \"total\": {\n",
    "            \"mean\": float(df_clustering['Total_Buah'].mean() + df_clustering['Total_Sayur'].mean()),\n",
    "            \"weekly_national\": float((df_clustering['Total_Buah'] + df_clustering['Total_Sayur']).sum()),\n",
    "            \"monthly_national\": float((df_clustering['Total_Buah'] + df_clustering['Total_Sayur']).sum() * 4),\n",
    "            \"yearly_national\": float((df_clustering['Total_Buah'] + df_clustering['Total_Sayur']).sum() * 52)\n",
    "        }\n",
    "    },\n",
    "    \"clusters\": []\n",
    "}\n",
    "\n",
    "# Add cluster information\n",
    "for _, row in df_profiles.iterrows():\n",
    "    cluster_info = {\n",
    "        \"id\": int(row['Cluster']),\n",
    "        \"size\": int(row['Count']),\n",
    "        \"percentage\": float(row['Count'] / len(df_clustering) * 100),\n",
    "        \"centroid\": {\n",
    "            \"buah\": float(row['Total_Buah_mean']),\n",
    "            \"sayur\": float(row['Total_Sayur_mean']),\n",
    "            \"total\": float(row['Total_Buah_mean'] + row['Total_Sayur_mean'])\n",
    "        }\n",
    "    }\n",
    "    summary_stats['clusters'].append(cluster_info)\n",
    "\n",
    "# Calculate YoY growth if 2023 data exists\n",
    "if 'Total_Pengeluaran_2023' in df_integrated.columns and 'Total_Pengeluaran_2024' in df_integrated.columns:\n",
    "    avg_2023 = df_integrated['Total_Pengeluaran_2023'].mean()\n",
    "    avg_2024 = df_integrated['Total_Pengeluaran_2024'].mean()\n",
    "    growth = ((avg_2024 - avg_2023) / avg_2023) * 100\n",
    "    summary_stats['growth'] = {\n",
    "        \"yoy_percentage\": float(growth),\n",
    "        \"avg_2023\": float(avg_2023),\n",
    "        \"avg_2024\": float(avg_2024)\n",
    "    }\n",
    "\n",
    "print(\"✓ Summary statistics generated\")\n",
    "print(f\"  Total Kabupaten: {summary_stats['metadata']['total_kabupaten']}\")\n",
    "print(f\"  Total Clusters: {summary_stats['metadata']['total_clusters']}\")\n",
    "print(f\"  Average Expenditure: Rp {summary_stats['expenditure']['total']['mean']:,.0f}/minggu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798e0499",
   "metadata": {},
   "source": [
    "## 4. Generate Visualization Data\n",
    "\n",
    "**Tujuan**: Menyiapkan data untuk berbagai chart di frontend.\n",
    "\n",
    "**Chart Types**:\n",
    "1. Cluster distribution (pie/donut chart)\n",
    "2. Expenditure comparison (bar chart)\n",
    "3. Regional distribution (map data)\n",
    "4. Time series (trend line)\n",
    "5. Scatter plot data (buah vs sayur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0751be",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_profiles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m visualization_data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster_distribution\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpenditure_comparison\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_regions\u001b[39m\u001b[38;5;124m\"\u001b[39m: []\n\u001b[0;32m      7\u001b[0m }\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 1. Cluster distribution for pie chart\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf_profiles\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     11\u001b[0m     visualization_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster_distribution\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCluster \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCluster\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpercentage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(df_clustering) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     15\u001b[0m     })\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 2. Expenditure comparison for bar chart\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_profiles' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "visualization_data = {\n",
    "    \"cluster_distribution\": [],\n",
    "    \"expenditure_comparison\": [],\n",
    "    \"regional_distribution\": [],\n",
    "    \"scatter_plot\": [],\n",
    "    \"top_regions\": []\n",
    "}\n",
    "\n",
    "# 1. Cluster distribution for pie chart\n",
    "for _, row in df_profiles.iterrows():\n",
    "    visualization_data[\"cluster_distribution\"].append({\n",
    "        \"cluster\": f\"Cluster {int(row['Cluster'])}\",\n",
    "        \"count\": int(row[\"Count\"]),\n",
    "        \"percentage\": float(row[\"Count\"] / len(df_clustering) * 100)\n",
    "    })\n",
    "\n",
    "# 2. Expenditure comparison for bar chart\n",
    "for _, row in df_profiles.iterrows():\n",
    "    visualization_data[\"expenditure_comparison\"].append({\n",
    "        \"cluster\": f\"Cluster {int(row['Cluster'])}\",\n",
    "        \"buah\": float(row[\"Total_Buah_mean\"]),\n",
    "        \"sayur\": float(row[\"Total_Sayur_mean\"]),\n",
    "        \"total\": float(row[\"Total_Buah_mean\"] + row[\"Total_Sayur_mean\"])\n",
    "    })\n",
    "\n",
    "# 3. Regional distribution\n",
    "# First, check if Region column exists, if not create a mapping from kabupaten to region\n",
    "if 'Region' not in df_clustering.columns:\n",
    "    # Define region mapping based on province prefixes\n",
    "    def get_region(kabupaten):\n",
    "        kabupaten_lower = str(kabupaten).lower()\n",
    "        if any(x in kabupaten_lower for x in ['aceh', 'sumatera', 'medan', 'padang', 'palembang', 'lampung', 'bengkulu', 'jambi', 'riau', 'bangka', 'belitung']):\n",
    "            return 'Sumatera'\n",
    "        elif any(x in kabupaten_lower for x in ['jakarta', 'bogor', 'depok', 'tangerang', 'bekasi', 'banten', 'jawa barat', 'bandung', 'cirebon', 'sukabumi', 'tasikmalaya']):\n",
    "            return 'Jawa Barat'\n",
    "        elif any(x in kabupaten_lower for x in ['jawa tengah', 'semarang', 'solo', 'surakarta', 'magelang', 'purwokerto', 'tegal', 'pekalongan', 'yogyakarta']):\n",
    "            return 'Jawa Tengah & DIY'\n",
    "        elif any(x in kabupaten_lower for x in ['jawa timur', 'surabaya', 'malang', 'kediri', 'blitar', 'jember', 'banyuwangi', 'madiun', 'madura']):\n",
    "            return 'Jawa Timur'\n",
    "        elif any(x in kabupaten_lower for x in ['bali', 'nusa tenggara', 'lombok', 'sumbawa', 'flores', 'timor', 'kupang']):\n",
    "            return 'Bali & Nusa Tenggara'\n",
    "        elif any(x in kabupaten_lower for x in ['kalimantan', 'pontianak', 'banjarmasin', 'samarinda', 'balikpapan', 'palangkaraya']):\n",
    "            return 'Kalimantan'\n",
    "        elif any(x in kabupaten_lower for x in ['sulawesi', 'makassar', 'manado', 'palu', 'kendari', 'gorontalo']):\n",
    "            return 'Sulawesi'\n",
    "        elif any(x in kabupaten_lower for x in ['maluku', 'ambon', 'ternate', 'papua', 'jayapura', 'sorong', 'merauke', 'nabire', 'timika']):\n",
    "            return 'Maluku & Papua'\n",
    "        else:\n",
    "            return 'Lainnya'\n",
    "    \n",
    "    df_clustering['Region'] = df_clustering['Kabupaten_Kota'].apply(get_region)\n",
    "\n",
    "# Group by region for regional distribution\n",
    "regional_stats = df_clustering.groupby('Region').agg({\n",
    "    'Kabupaten_Kota': 'count',\n",
    "    'Total_Buah': 'mean',\n",
    "    'Total_Sayur': 'mean',\n",
    "    'Total_Pengeluaran': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "regional_stats.columns = ['region', 'count', 'avg_buah', 'avg_sayur', 'avg_total']\n",
    "\n",
    "for _, row in regional_stats.iterrows():\n",
    "    visualization_data['regional_distribution'].append({\n",
    "        \"region\": str(row['region']),\n",
    "        \"count\": int(row['count']),\n",
    "        \"avg_buah\": float(row['avg_buah']),\n",
    "        \"avg_sayur\": float(row['avg_sayur']),\n",
    "        \"avg_total\": float(row['avg_total'])\n",
    "    })\n",
    "\n",
    "# 4. Scatter plot data (sample 100 points for performance)\n",
    "sample_data = df_clustering.sample(n=min(100, len(df_clustering)), random_state=42)\n",
    "for _, row in sample_data.iterrows():\n",
    "    visualization_data['scatter_plot'].append({\n",
    "        \"kabupaten\": str(row['Kabupaten_Kota']),\n",
    "        \"buah\": float(row['Total_Buah']),\n",
    "        \"sayur\": float(row['Total_Sayur']),\n",
    "        \"cluster\": int(row['Cluster']),\n",
    "        \"region\": str(row['Region'])\n",
    "    })\n",
    "\n",
    "# 5. Top regions by expenditure\n",
    "top_regions = df_clustering.nlargest(10, 'Total_Pengeluaran')[['Kabupaten_Kota', 'Region', 'Total_Buah', 'Total_Sayur', 'Total_Pengeluaran', 'Cluster']]\n",
    "\n",
    "for _, row in top_regions.iterrows():\n",
    "    visualization_data['top_regions'].append({\n",
    "        \"kabupaten\": str(row['Kabupaten_Kota']),\n",
    "        \"region\": str(row['Region']),\n",
    "        \"buah\": float(row['Total_Buah']),\n",
    "        \"sayur\": float(row['Total_Sayur']),\n",
    "        \"total\": float(row['Total_Pengeluaran']),\n",
    "        \"cluster\": int(row['Cluster'])\n",
    "    })\n",
    "\n",
    "print(\"✓ Visualization data generated\")\n",
    "print(f\"  Cluster distribution: {len(visualization_data['cluster_distribution'])} entries\")\n",
    "print(f\"  Expenditure comparison: {len(visualization_data['expenditure_comparison'])} entries\")\n",
    "print(f\"  Regional distribution: {len(visualization_data['regional_distribution'])} entries\")\n",
    "print(f\"  Scatter plot: {len(visualization_data['scatter_plot'])} points\")\n",
    "print(f\"  Top regions: {len(visualization_data['top_regions'])} regions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46993e94",
   "metadata": {},
   "source": [
    "Saya akan membuat file API notebook untuk implementasi hasil modeling ke frontend. \n",
    "\n",
    "Created [](file:///d%3A/Perkuliahan/2025-2026/Analisa%20Big%20Data/ProjectABD/api.ipynb)\n",
    "\n",
    "File api.ipynb berhasil dibuat! Notebook ini menyediakan:\n",
    "\n",
    "**Fitur Utama**:\n",
    "1. **Summary Statistics** - Statistik ringkasan untuk dashboard cards (JSON)\n",
    "2. **Visualization Data** - Data terstruktur untuk berbagai chart (JSON)\n",
    "3. **Predictions 2025** - Prediksi pengeluaran tahun depan berdasarkan trend (CSV)\n",
    "4. **Auto-copy** - Otomatis copy semua file ke folder data\n",
    "\n",
    "**Output Files**:\n",
    "- `summary_statistics.json` - Metadata & statistik agregat\n",
    "- `visualization_data.json` - Data untuk pie chart, bar chart, scatter plot\n",
    "- `predictions_2025.csv` - Forecast untuk tahun 2025\n",
    "- Copy semua clustering results ke frontend\n",
    "\n",
    "Jalankan notebook ini setelah modeling selesai untuk mempersiapkan data yang siap dikonsumsi frontend!\n",
    "\n",
    "Made changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a96d9",
   "metadata": {},
   "source": [
    "Saya akan membuat file API notebook untuk implementasi hasil modeling ke frontend. \n",
    "\n",
    "Created [](file:///d%3A/Perkuliahan/2025-2026/Analisa%20Big%20Data/ProjectABD/api.ipynb)\n",
    "\n",
    "File api.ipynb berhasil dibuat! Notebook ini menyediakan:\n",
    "\n",
    "**Fitur Utama**:\n",
    "1. **Summary Statistics** - Statistik ringkasan untuk dashboard cards (JSON)\n",
    "2. **Visualization Data** - Data terstruktur untuk berbagai chart (JSON)\n",
    "3. **Predictions 2025** - Prediksi pengeluaran tahun depan berdasarkan trend (CSV)\n",
    "4. **Auto-copy** - Otomatis copy semua file ke folder data\n",
    "\n",
    "**Output Files**:\n",
    "- `summary_statistics.json` - Metadata & statistik agregat\n",
    "- `visualization_data.json` - Data untuk pie chart, bar chart, scatter plot\n",
    "- `predictions_2025.csv` - Forecast untuk tahun 2025\n",
    "- Copy semua clustering results ke frontend\n",
    "\n",
    "Jalankan notebook ini setelah modeling selesai untuk mempersiapkan data yang siap dikonsumsi frontend!\n",
    "\n",
    "Made changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786c778d",
   "metadata": {},
   "source": [
    "## 5. Generate Predictions for 2025\n",
    "\n",
    "**Tujuan**: Membuat prediksi pengeluaran untuk tahun 2025 berdasarkan trend historis.\n",
    "\n",
    "**Metode**: Simple linear growth model berdasarkan data 2023-2024.\n",
    "\n",
    "**Assumptions**:\n",
    "- Pertumbuhan linear dari 2023 ke 2024 akan berlanjut ke 2025\n",
    "- Tidak ada shock ekonomi atau perubahan drastis\n",
    "- Pattern konsumsi tetap konsisten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e938c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_clustering' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate growth rates from integrated data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mdf_clustering\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Get 2023 data if available\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal_Pengeluaran_2023\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_integrated\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Merge with integrated data to get 2023 values\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_clustering' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Calculate growth rates from integrated data\n",
    "df_predictions = df_clustering.copy()\n",
    "\n",
    "# Get 2023 data if available\n",
    "if 'Total_Pengeluaran_2023' in df_integrated.columns:\n",
    "    # Merge with integrated data to get 2023 values\n",
    "    df_with_history = df_clustering.merge(\n",
    "        df_integrated[['Kabupaten_Kota', 'Total_Pengeluaran_2023']],\n",
    "        on='Kabupaten_Kota',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Calculate growth rate\n",
    "    df_with_history['Growth_Rate'] = (\n",
    "        (df_with_history['Pengeluaran_Buah'] + df_with_history['Pengeluaran_Sayur'] - df_with_history['Total_Pengeluaran_2023']) \n",
    "        / df_with_history['Total_Pengeluaran_2023']\n",
    "    )\n",
    "    \n",
    "    # Fill NaN growth rates with average\n",
    "    avg_growth_rate = df_with_history['Growth_Rate'].mean()\n",
    "    df_with_history['Growth_Rate'].fillna(avg_growth_rate, inplace=True)\n",
    "    \n",
    "    # Predict 2025 (apply same growth rate)\n",
    "    df_predictions['Pengeluaran_Buah_2025'] = df_with_history['Pengeluaran_Buah'] * (1 + df_with_history['Growth_Rate'])\n",
    "    df_predictions['Pengeluaran_Sayur_2025'] = df_with_history['Pengeluaran_Sayur'] * (1 + df_with_history['Growth_Rate'])\n",
    "else:\n",
    "    # If no 2023 data, assume 5% growth (conservative estimate)\n",
    "    default_growth = 0.05\n",
    "    df_predictions['Pengeluaran_Buah_2025'] = df_predictions['Pengeluaran_Buah'] * (1 + default_growth)\n",
    "    df_predictions['Pengeluaran_Sayur_2025'] = df_predictions['Pengeluaran_Sayur'] * (1 + default_growth)\n",
    "\n",
    "df_predictions['Total_Pengeluaran_2025'] = df_predictions['Pengeluaran_Buah_2025'] + df_predictions['Pengeluaran_Sayur_2025']\n",
    "df_predictions['Tahun'] = 2025\n",
    "\n",
    "# Select columns for export\n",
    "predictions_export = df_predictions[[\n",
    "    'Kabupaten_Kota', 'Region', 'Cluster',\n",
    "    'Pengeluaran_Buah_2025', 'Pengeluaran_Sayur_2025', 'Total_Pengeluaran_2025', 'Tahun'\n",
    "]].copy()\n",
    "\n",
    "predictions_export.rename(columns={\n",
    "    'Pengeluaran_Buah_2025': 'Pengeluaran_Buah',\n",
    "    'Pengeluaran_Sayur_2025': 'Pengeluaran_Sayur',\n",
    "    'Total_Pengeluaran_2025': 'Total_Pengeluaran'\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"✓ Predictions generated for 2025\")\n",
    "print(f\"  Total predictions: {len(predictions_export)}\")\n",
    "print(f\"  Average predicted buah: Rp {predictions_export['Pengeluaran_Buah'].mean():,.0f}\")\n",
    "print(f\"  Average predicted sayur: Rp {predictions_export['Pengeluaran_Sayur'].mean():,.0f}\")\n",
    "print(f\"  Average predicted total: Rp {predictions_export['Total_Pengeluaran'].mean():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbac395",
   "metadata": {},
   "source": [
    "## 6. Export Files\n",
    "\n",
    "**Output Files**:\n",
    "1. `summary_statistics.json` - Statistik ringkasan\n",
    "2. `visualization_data.json` - Data untuk chart\n",
    "3. `predictions_2025.csv` - Prediksi tahun 2025\n",
    "4. Copy clustering files ke frontend public folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4767bbcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EXPORTING FILES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Export summary statistics JSON\n",
    "with open(output_dir / 'summary_statistics.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary_stats, f, indent=2, ensure_ascii=False)\n",
    "print(f\"✓ Exported: summary_statistics.json\")\n",
    "\n",
    "# 2. Export visualization data JSON\n",
    "with open(output_dir / 'visualization_data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(visualization_data, f, indent=2, ensure_ascii=False)\n",
    "print(f\"✓ Exported: visualization_data.json\")\n",
    "\n",
    "# 3. Export predictions CSV\n",
    "predictions_export.to_csv(output_dir / 'predictions_2025.csv', index=False)\n",
    "print(f\"✓ Exported: predictions_2025.csv ({predictions_export.shape})\")\n",
    "\n",
    "# 4. Copy clustering files to frontend public folder\n",
    "import shutil\n",
    "\n",
    "files_to_copy = [\n",
    "    'clustering_results.csv',\n",
    "    'cluster_profiles.csv',\n",
    "    'cluster_centroids.csv'\n",
    "]\n",
    "\n",
    "for filename in files_to_copy:\n",
    "    src = modeling_dir / filename\n",
    "    dst = output_dir / filename\n",
    "    shutil.copy2(src, dst)\n",
    "    print(f\"✓ Copied: {filename}\")\n",
    "\n",
    "# 5. Copy integrated data to frontend\n",
    "frontend_cleaned_dir = Path('frontend/public/data/cleaned')\n",
    "frontend_cleaned_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "shutil.copy2(cleaned_dir / 'data_integrated_wide.csv', frontend_cleaned_dir / 'data_integrated_wide.csv')\n",
    "print(f\"✓ Copied: data_integrated_wide.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ ALL FILES EXPORTED SUCCESSFULLY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nOutput directory: {output_dir.absolute()}\")\n",
    "print(f\"\\nFiles ready for frontend integration:\")\n",
    "print(f\"  - summary_statistics.json\")\n",
    "print(f\"  - visualization_data.json\")\n",
    "print(f\"  - predictions_2025.csv\")\n",
    "print(f\"  - clustering_results.csv\")\n",
    "print(f\"  - cluster_profiles.csv\")\n",
    "print(f\"  - cluster_centroids.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28737b5b",
   "metadata": {},
   "source": [
    "## 7. Validation & Preview\n",
    "\n",
    "**Tujuan**: Validasi data yang diekspor dan preview sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a6f0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DATA VALIDATION & PREVIEW\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Validate JSON files\n",
    "print(\"\\n1. Summary Statistics Sample:\")\n",
    "print(f\"   Total Kabupaten: {summary_stats['metadata']['total_kabupaten']}\")\n",
    "print(f\"   Total Clusters: {summary_stats['metadata']['total_clusters']}\")\n",
    "print(f\"   Average Buah: Rp {summary_stats['expenditure']['buah']['mean']:,.0f}\")\n",
    "print(f\"   Average Sayur: Rp {summary_stats['expenditure']['sayur']['mean']:,.0f}\")\n",
    "\n",
    "print(\"\\n2. Visualization Data Sample:\")\n",
    "print(f\"   Cluster distribution entries: {len(visualization_data['cluster_distribution'])}\")\n",
    "print(f\"   First cluster: {visualization_data['cluster_distribution'][0]}\")\n",
    "\n",
    "print(\"\\n3. Predictions 2025 Sample:\")\n",
    "print(predictions_export.head())\n",
    "\n",
    "print(\"\\n4. File Sizes:\")\n",
    "for file in output_dir.glob('*'):\n",
    "    size_kb = file.stat().st_size / 1024\n",
    "    print(f\"   {file.name}: {size_kb:.2f} KB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ VALIDATION COMPLETE - Data ready for frontend\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
